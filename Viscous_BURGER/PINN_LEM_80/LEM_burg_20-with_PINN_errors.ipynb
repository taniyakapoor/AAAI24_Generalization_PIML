{
 "cells": [
  {
   "cell_type": "raw",
   "id": "0d296d5d",
   "metadata": {},
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1682ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LEMCell\n",
    "class LEMCell(nn.Module):\n",
    "    def __init__(self, ninp, nhid, dt):\n",
    "        super(LEMCell, self).__init__()\n",
    "        self.ninp = ninp\n",
    "        self.nhid = nhid\n",
    "        self.dt = dt\n",
    "        self.inp2hid = nn.Linear(ninp, 4 * nhid)\n",
    "        self.hid2hid = nn.Linear(nhid, 3 * nhid)\n",
    "        self.transform_z = nn.Linear(nhid, nhid)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        std = 1.0 / np.sqrt(self.nhid)\n",
    "        for w in self.parameters():\n",
    "            w.data.uniform_(-std, std)\n",
    "\n",
    "    def forward(self, x, y, z):\n",
    "        transformed_inp = self.inp2hid(x)\n",
    "        transformed_hid = self.hid2hid(y)\n",
    "        i_dt1, i_dt2, i_z, i_y = transformed_inp.chunk(4, 1)\n",
    "        h_dt1, h_dt2, h_y = transformed_hid.chunk(3, 1)\n",
    "\n",
    "        ms_dt_bar = self.dt * torch.sigmoid(i_dt1 + h_dt1)\n",
    "        ms_dt = self.dt * torch.sigmoid(i_dt2 + h_dt2)\n",
    "\n",
    "        z = (1. - ms_dt) * z + ms_dt * torch.tanh(i_y + h_y)\n",
    "        y = (1. - ms_dt_bar) * y + ms_dt_bar * torch.tanh(self.transform_z(z) + i_z)\n",
    "\n",
    "        return y, z\n",
    "\n",
    "# Define the LEM model\n",
    "class LEM(nn.Module):\n",
    "    def __init__(self, ninp, nhid, nout, dt=1.):\n",
    "        super(LEM, self).__init__()\n",
    "        self.nhid = nhid\n",
    "        self.cell = LEMCell(ninp, nhid, dt)\n",
    "        self.classifier = nn.Linear(nhid, nout)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        for name, param in self.named_parameters():\n",
    "            if 'classifier' in name and 'weight' in name:\n",
    "                nn.init.kaiming_normal_(param.data)\n",
    "\n",
    "    def forward(self, input):\n",
    "        y = input.data.new(input.size(1), self.nhid).zero_()\n",
    "        z = input.data.new(input.size(1), self.nhid).zero_()\n",
    "        for x in input:\n",
    "            y, z = self.cell(x, y, z)\n",
    "        out = self.classifier(y)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a982afa5",
   "metadata": {},
   "source": [
    "### PINN data importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79da65b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing data\n",
    "\n",
    "# Load the .mat file\n",
    "mat_data = scipy.io.loadmat('burg.mat')\n",
    "\n",
    "# Access the variables stored in the .mat file\n",
    "# The variable names in the .mat file become keys in the loaded dictionary\n",
    "x = mat_data['x']\n",
    "t = mat_data['t']\n",
    "u = mat_data['u1']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbac9f8e",
   "metadata": {},
   "source": [
    "### Exact Solution data importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9967dbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing data\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import time\n",
    "import scipy.io\n",
    "\n",
    "# Load the .mat file\n",
    "mat_data = scipy.io.loadmat('burgers_shock.mat')\n",
    "\n",
    "# Access the variables stored in the .mat file\n",
    "# The variable names in the .mat file become keys in the loaded dictionary\n",
    "x = mat_data['x']\n",
    "t = mat_data['t']\n",
    "u_1 = mat_data['usol']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19e5ee39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 100)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1749932c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11699/1797348989.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  u_test_full_tensor = torch.tensor(u_1**2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 100])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new dataset generation with errors\n",
    "u_1 = torch.tensor(u_1)\n",
    "u = torch.tensor(u) + 0.5\n",
    "k1 = ( u - u_1)**2\n",
    "u_test_full_tensor = torch.tensor(u_1**2)\n",
    "u_test_full_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1cdf9f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relative Error Test:  0.66240856126090141842155389895197004079818725585938 %\n"
     ]
    }
   ],
   "source": [
    "# Compute the relative L2 error norm (generalization error)\n",
    "relative_error_test = torch.mean(k1) / torch.mean(u_test_full_tensor)\n",
    "\n",
    "# Format the relative error to display 10 digits of magnitude\n",
    "formatted_relative_error_test = \"{:.50f}\".format(relative_error_test.item())\n",
    "\n",
    "print(\"Relative Error Test: \", formatted_relative_error_test, \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83a01b14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 100])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Toy problem data\n",
    "input_size = 256\n",
    "hidden_size = 32\n",
    "output_size = 256\n",
    "sequence_length = 79\n",
    "batch_size = 1\n",
    "num_epochs = 20000\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "u[:, 0:100].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61514f6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0496e4a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test data shape torch.Size([256])\n",
      "input data shape torch.Size([256, 79])\n",
      "Target data shape torch.Size([256, 79])\n",
      "input tensor shape torch.Size([1, 79, 256])\n",
      "Target tensor shape torch.Size([1, 79, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11699/3906878071.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_tensor = torch.tensor(input_data.T).view(batch_size, sequence_length, input_size).float()\n",
      "/tmp/ipykernel_11699/3906878071.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  target_tensor = torch.tensor(target_data.T).view(batch_size, sequence_length, output_size).float()\n"
     ]
    }
   ],
   "source": [
    "input_data = u[:,0:79]\n",
    "target_data = u[:,1:80]\n",
    "\n",
    "test_data = u[:,79]\n",
    "#test_target = u[:,80:100]\n",
    "\n",
    "print(\"test data shape\", test_data.shape)\n",
    "#print(\"test target shape\", test_target.shape)\n",
    "\n",
    "print(\"input data shape\",input_data.shape)\n",
    "print(\"Target data shape\",target_data.shape)\n",
    "\n",
    "# Convert data to tensors\n",
    "input_tensor = torch.tensor(input_data.T).view(batch_size, sequence_length, input_size).float()\n",
    "target_tensor = torch.tensor(target_data.T).view(batch_size, sequence_length, output_size).float()\n",
    "\n",
    "print(\"input tensor shape\",input_tensor.shape)\n",
    "print(\"Target tensor shape\",target_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "718d5b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11699/546962278.py:2: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matricesor `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorShape.cpp:2981.)\n",
      "  test_tensor = torch.tensor(test_data.T).view(batch_size, 1, input_size).float()\n",
      "/tmp/ipykernel_11699/546962278.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_tensor = torch.tensor(test_data.T).view(batch_size, 1, input_size).float()\n"
     ]
    }
   ],
   "source": [
    "# Convert test data to tensors\n",
    "test_tensor = torch.tensor(test_data.T).view(batch_size, 1, input_size).float()\n",
    "#test_target_tensor = torch.tensor(test_target.T).view(batch_size, 20, output_size).float()\n",
    "target_tensor = torch.squeeze(target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d733ab9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/20000, Loss: 0.6200895905494690\n",
      "Epoch: 20/20000, Loss: 0.5730171799659729\n",
      "Epoch: 30/20000, Loss: 0.5228640437126160\n",
      "Epoch: 40/20000, Loss: 0.4732925891876221\n",
      "Epoch: 50/20000, Loss: 0.4271131157875061\n",
      "Epoch: 60/20000, Loss: 0.3852492868900299\n",
      "Epoch: 70/20000, Loss: 0.3494604229927063\n",
      "Epoch: 80/20000, Loss: 0.3178244531154633\n",
      "Epoch: 90/20000, Loss: 0.2895337343215942\n",
      "Epoch: 100/20000, Loss: 0.2640845775604248\n",
      "Epoch: 110/20000, Loss: 0.2410973161458969\n",
      "Epoch: 120/20000, Loss: 0.2202756404876709\n",
      "Epoch: 130/20000, Loss: 0.2013816386461258\n",
      "Epoch: 140/20000, Loss: 0.1842183172702789\n",
      "Epoch: 150/20000, Loss: 0.1686185002326965\n",
      "Epoch: 160/20000, Loss: 0.1544376611709595\n",
      "Epoch: 170/20000, Loss: 0.1415487378835678\n",
      "Epoch: 180/20000, Loss: 0.1298387646675110\n",
      "Epoch: 190/20000, Loss: 0.1192062497138977\n",
      "Epoch: 200/20000, Loss: 0.1095592901110649\n",
      "Epoch: 210/20000, Loss: 0.1008141413331032\n",
      "Epoch: 220/20000, Loss: 0.0928942859172821\n",
      "Epoch: 230/20000, Loss: 0.0857293680310249\n",
      "Epoch: 240/20000, Loss: 0.0792546942830086\n",
      "Epoch: 250/20000, Loss: 0.0734106004238129\n",
      "Epoch: 260/20000, Loss: 0.0681420639157295\n",
      "Epoch: 270/20000, Loss: 0.0633982792496681\n",
      "Epoch: 280/20000, Loss: 0.0591324120759964\n",
      "Epoch: 290/20000, Loss: 0.0553012117743492\n",
      "Epoch: 300/20000, Loss: 0.0518648587167263\n",
      "Epoch: 310/20000, Loss: 0.0487866811454296\n",
      "Epoch: 320/20000, Loss: 0.0460329614579678\n",
      "Epoch: 330/20000, Loss: 0.0435727424919605\n",
      "Epoch: 340/20000, Loss: 0.0413776338100433\n",
      "Epoch: 350/20000, Loss: 0.0394216440618038\n",
      "Epoch: 360/20000, Loss: 0.0376810282468796\n",
      "Epoch: 370/20000, Loss: 0.0361340902745724\n",
      "Epoch: 380/20000, Loss: 0.0347610898315907\n",
      "Epoch: 390/20000, Loss: 0.0335440561175346\n",
      "Epoch: 400/20000, Loss: 0.0324666760861874\n",
      "Epoch: 410/20000, Loss: 0.0315141752362251\n",
      "Epoch: 420/20000, Loss: 0.0306731443852186\n",
      "Epoch: 430/20000, Loss: 0.0299315117299557\n",
      "Epoch: 440/20000, Loss: 0.0292783658951521\n",
      "Epoch: 450/20000, Loss: 0.0287038832902908\n",
      "Epoch: 460/20000, Loss: 0.0281992312520742\n",
      "Epoch: 470/20000, Loss: 0.0277564860880375\n",
      "Epoch: 480/20000, Loss: 0.0273685492575169\n",
      "Epoch: 490/20000, Loss: 0.0270290561020374\n",
      "Epoch: 500/20000, Loss: 0.0267323292791843\n",
      "Epoch: 510/20000, Loss: 0.0264733079820871\n",
      "Epoch: 520/20000, Loss: 0.0262474808841944\n",
      "Epoch: 530/20000, Loss: 0.0260508339852095\n",
      "Epoch: 540/20000, Loss: 0.0258798003196716\n",
      "Epoch: 550/20000, Loss: 0.0257312320172787\n",
      "Epoch: 560/20000, Loss: 0.0256023220717907\n",
      "Epoch: 570/20000, Loss: 0.0254906062036753\n",
      "Epoch: 580/20000, Loss: 0.0253938995301723\n",
      "Epoch: 590/20000, Loss: 0.0253102779388428\n",
      "Epoch: 600/20000, Loss: 0.0252380408346653\n",
      "Epoch: 610/20000, Loss: 0.0251757074147463\n",
      "Epoch: 620/20000, Loss: 0.0251219570636749\n",
      "Epoch: 630/20000, Loss: 0.0250756461173296\n",
      "Epoch: 640/20000, Loss: 0.0250357650220394\n",
      "Epoch: 650/20000, Loss: 0.0250014103949070\n",
      "Epoch: 660/20000, Loss: 0.0249717999249697\n",
      "Epoch: 670/20000, Loss: 0.0249461941421032\n",
      "Epoch: 680/20000, Loss: 0.0249238591641188\n",
      "Epoch: 690/20000, Loss: 0.0249037612229586\n",
      "Epoch: 700/20000, Loss: 0.0248822811990976\n",
      "Epoch: 710/20000, Loss: 0.0246948525309563\n",
      "Epoch: 720/20000, Loss: 0.0239805392920971\n",
      "Epoch: 730/20000, Loss: 0.0234844703227282\n",
      "Epoch: 740/20000, Loss: 0.0230021346360445\n",
      "Epoch: 750/20000, Loss: 0.0225791148841381\n",
      "Epoch: 760/20000, Loss: 0.0221749059855938\n",
      "Epoch: 770/20000, Loss: 0.0217993222177029\n",
      "Epoch: 780/20000, Loss: 0.0214496646076441\n",
      "Epoch: 790/20000, Loss: 0.0211235880851746\n",
      "Epoch: 800/20000, Loss: 0.0208188071846962\n",
      "Epoch: 810/20000, Loss: 0.0205325242131948\n",
      "Epoch: 820/20000, Loss: 0.0202601831406355\n",
      "Epoch: 830/20000, Loss: 0.0199675746262074\n",
      "Epoch: 840/20000, Loss: 0.0193910486996174\n",
      "Epoch: 850/20000, Loss: 0.0188438538461924\n",
      "Epoch: 860/20000, Loss: 0.0183485485613346\n",
      "Epoch: 870/20000, Loss: 0.0178895518183708\n",
      "Epoch: 880/20000, Loss: 0.0174518171697855\n",
      "Epoch: 890/20000, Loss: 0.0170293375849724\n",
      "Epoch: 900/20000, Loss: 0.0166213940829039\n",
      "Epoch: 910/20000, Loss: 0.0162286963313818\n",
      "Epoch: 920/20000, Loss: 0.0158518757671118\n",
      "Epoch: 930/20000, Loss: 0.0154905607923865\n",
      "Epoch: 940/20000, Loss: 0.0151433143764734\n",
      "Epoch: 950/20000, Loss: 0.0148099223151803\n",
      "Epoch: 960/20000, Loss: 0.0144915916025639\n",
      "Epoch: 970/20000, Loss: 0.0141880810260773\n",
      "Epoch: 980/20000, Loss: 0.0138984778895974\n",
      "Epoch: 990/20000, Loss: 0.0136218052357435\n",
      "Epoch: 1000/20000, Loss: 0.0133571242913604\n",
      "Epoch: 1010/20000, Loss: 0.0131035381928086\n",
      "Epoch: 1020/20000, Loss: 0.0128601910546422\n",
      "Epoch: 1030/20000, Loss: 0.0126262865960598\n",
      "Epoch: 1040/20000, Loss: 0.0124010816216469\n",
      "Epoch: 1050/20000, Loss: 0.0121838906779885\n",
      "Epoch: 1060/20000, Loss: 0.0119740972295403\n",
      "Epoch: 1070/20000, Loss: 0.0117711750790477\n",
      "Epoch: 1080/20000, Loss: 0.0115746790543199\n",
      "Epoch: 1090/20000, Loss: 0.0113842021673918\n",
      "Epoch: 1100/20000, Loss: 0.0111993588507175\n",
      "Epoch: 1110/20000, Loss: 0.0110197644680738\n",
      "Epoch: 1120/20000, Loss: 0.0108450651168823\n",
      "Epoch: 1130/20000, Loss: 0.0106749562546611\n",
      "Epoch: 1140/20000, Loss: 0.0105091650038958\n",
      "Epoch: 1150/20000, Loss: 0.0103474268689752\n",
      "Epoch: 1160/20000, Loss: 0.0101895248517394\n",
      "Epoch: 1170/20000, Loss: 0.0100352698937058\n",
      "Epoch: 1180/20000, Loss: 0.0098844766616821\n",
      "Epoch: 1190/20000, Loss: 0.0097370687872171\n",
      "Epoch: 1200/20000, Loss: 0.0095926243811846\n",
      "Epoch: 1210/20000, Loss: 0.0094511220231652\n",
      "Epoch: 1220/20000, Loss: 0.0093123847618699\n",
      "Epoch: 1230/20000, Loss: 0.0091759385541081\n",
      "Epoch: 1240/20000, Loss: 0.0090408213436604\n",
      "Epoch: 1250/20000, Loss: 0.0089067872613668\n",
      "Epoch: 1260/20000, Loss: 0.0087738791480660\n",
      "Epoch: 1270/20000, Loss: 0.0086440332233906\n",
      "Epoch: 1280/20000, Loss: 0.0085177719593048\n",
      "Epoch: 1290/20000, Loss: 0.0083947395905852\n",
      "Epoch: 1300/20000, Loss: 0.0082745021209121\n",
      "Epoch: 1310/20000, Loss: 0.0081567307934165\n",
      "Epoch: 1320/20000, Loss: 0.0080412020906806\n",
      "Epoch: 1330/20000, Loss: 0.0079277670010924\n",
      "Epoch: 1340/20000, Loss: 0.0078163109719753\n",
      "Epoch: 1350/20000, Loss: 0.0077067166566849\n",
      "Epoch: 1360/20000, Loss: 0.0075926440767944\n",
      "Epoch: 1370/20000, Loss: 0.0073473188094795\n",
      "Epoch: 1380/20000, Loss: 0.0071948417462409\n",
      "Epoch: 1390/20000, Loss: 0.0070387213490903\n",
      "Epoch: 1400/20000, Loss: 0.0068846275098622\n",
      "Epoch: 1410/20000, Loss: 0.0067320819944143\n",
      "Epoch: 1420/20000, Loss: 0.0065811006352305\n",
      "Epoch: 1430/20000, Loss: 0.0064332280308008\n",
      "Epoch: 1440/20000, Loss: 0.0062882220372558\n",
      "Epoch: 1450/20000, Loss: 0.0061464239843190\n",
      "Epoch: 1460/20000, Loss: 0.0060081300325692\n",
      "Epoch: 1470/20000, Loss: 0.0058735520578921\n",
      "Epoch: 1480/20000, Loss: 0.0057428381405771\n",
      "Epoch: 1490/20000, Loss: 0.0056160599924624\n",
      "Epoch: 1500/20000, Loss: 0.0054932129569352\n",
      "Epoch: 1510/20000, Loss: 0.0053742341697216\n",
      "Epoch: 1520/20000, Loss: 0.0052590179257095\n",
      "Epoch: 1530/20000, Loss: 0.0051474315114319\n",
      "Epoch: 1540/20000, Loss: 0.0050393273122609\n",
      "Epoch: 1550/20000, Loss: 0.0049345530569553\n",
      "Epoch: 1560/20000, Loss: 0.0048329583369195\n",
      "Epoch: 1570/20000, Loss: 0.0047343983314931\n",
      "Epoch: 1580/20000, Loss: 0.0046387319453061\n",
      "Epoch: 1590/20000, Loss: 0.0045458287931979\n",
      "Epoch: 1600/20000, Loss: 0.0044555673375726\n",
      "Epoch: 1610/20000, Loss: 0.0043678306974471\n",
      "Epoch: 1620/20000, Loss: 0.0042825131677091\n",
      "Epoch: 1630/20000, Loss: 0.0041995160281658\n",
      "Epoch: 1640/20000, Loss: 0.0041187456808984\n",
      "Epoch: 1650/20000, Loss: 0.0040401145815849\n",
      "Epoch: 1660/20000, Loss: 0.0039635421708226\n",
      "Epoch: 1670/20000, Loss: 0.0038889537099749\n",
      "Epoch: 1680/20000, Loss: 0.0038162772543728\n",
      "Epoch: 1690/20000, Loss: 0.0037454457487911\n",
      "Epoch: 1700/20000, Loss: 0.0036763967946172\n",
      "Epoch: 1710/20000, Loss: 0.0036090710200369\n",
      "Epoch: 1720/20000, Loss: 0.0035434123128653\n",
      "Epoch: 1730/20000, Loss: 0.0034793668892235\n",
      "Epoch: 1740/20000, Loss: 0.0034168844576925\n",
      "Epoch: 1750/20000, Loss: 0.0033559177536517\n",
      "Epoch: 1760/20000, Loss: 0.0032964195124805\n",
      "Epoch: 1770/20000, Loss: 0.0032383471261710\n",
      "Epoch: 1780/20000, Loss: 0.0031816586852074\n",
      "Epoch: 1790/20000, Loss: 0.0031263132113963\n",
      "Epoch: 1800/20000, Loss: 0.0030722729861736\n",
      "Epoch: 1810/20000, Loss: 0.0030195002909750\n",
      "Epoch: 1820/20000, Loss: 0.0029679592698812\n",
      "Epoch: 1830/20000, Loss: 0.0029176168609411\n",
      "Epoch: 1840/20000, Loss: 0.0028684374410659\n",
      "Epoch: 1850/20000, Loss: 0.0028203902766109\n",
      "Epoch: 1860/20000, Loss: 0.0027734418399632\n",
      "Epoch: 1870/20000, Loss: 0.0027275609318167\n",
      "Epoch: 1880/20000, Loss: 0.0026827156543732\n",
      "Epoch: 1890/20000, Loss: 0.0026388710830361\n",
      "Epoch: 1900/20000, Loss: 0.0025959883350879\n",
      "Epoch: 1910/20000, Loss: 0.0025540126953274\n",
      "Epoch: 1920/20000, Loss: 0.0025128379929811\n",
      "Epoch: 1930/20000, Loss: 0.0024721156805754\n",
      "Epoch: 1940/20000, Loss: 0.0024292038287967\n",
      "Epoch: 1950/20000, Loss: 0.0023426425177604\n",
      "Epoch: 1960/20000, Loss: 0.0022889538668096\n",
      "Epoch: 1970/20000, Loss: 0.0022418468724936\n",
      "Epoch: 1980/20000, Loss: 0.0021981294266880\n",
      "Epoch: 1990/20000, Loss: 0.0021565002389252\n",
      "Epoch: 2000/20000, Loss: 0.0021165150683373\n",
      "Epoch: 2010/20000, Loss: 0.0020777648314834\n",
      "Epoch: 2020/20000, Loss: 0.0020399538334459\n",
      "Epoch: 2030/20000, Loss: 0.0020029295701534\n",
      "Epoch: 2040/20000, Loss: 0.0019665395375341\n",
      "Epoch: 2050/20000, Loss: 0.0019305886235088\n",
      "Epoch: 2060/20000, Loss: 0.0018948973156512\n",
      "Epoch: 2070/20000, Loss: 0.0018594164866954\n",
      "Epoch: 2080/20000, Loss: 0.0018243463709950\n",
      "Epoch: 2090/20000, Loss: 0.0017899366794154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2100/20000, Loss: 0.0017563538858667\n",
      "Epoch: 2110/20000, Loss: 0.0017236637650058\n",
      "Epoch: 2120/20000, Loss: 0.0016926768003032\n",
      "Epoch: 2130/20000, Loss: 0.0016609588637948\n",
      "Epoch: 2140/20000, Loss: 0.0016305827302858\n",
      "Epoch: 2150/20000, Loss: 0.0016010531689972\n",
      "Epoch: 2160/20000, Loss: 0.0015722139505669\n",
      "Epoch: 2170/20000, Loss: 0.0015440201386809\n",
      "Epoch: 2180/20000, Loss: 0.0015164719661698\n",
      "Epoch: 2190/20000, Loss: 0.0014895525528118\n",
      "Epoch: 2200/20000, Loss: 0.0014632423408329\n",
      "Epoch: 2210/20000, Loss: 0.0014375277096406\n",
      "Epoch: 2220/20000, Loss: 0.0014123944565654\n",
      "Epoch: 2230/20000, Loss: 0.0013878301251680\n",
      "Epoch: 2240/20000, Loss: 0.0013638219097629\n",
      "Epoch: 2250/20000, Loss: 0.0013403579359874\n",
      "Epoch: 2260/20000, Loss: 0.0013174265623093\n",
      "Epoch: 2270/20000, Loss: 0.0012950164964423\n",
      "Epoch: 2280/20000, Loss: 0.0012731159804389\n",
      "Epoch: 2290/20000, Loss: 0.0012517139548436\n",
      "Epoch: 2300/20000, Loss: 0.0012307993602008\n",
      "Epoch: 2310/20000, Loss: 0.0012103611370549\n",
      "Epoch: 2320/20000, Loss: 0.0011903881095350\n",
      "Epoch: 2330/20000, Loss: 0.0011708691017702\n",
      "Epoch: 2340/20000, Loss: 0.0011517934035510\n",
      "Epoch: 2350/20000, Loss: 0.0011335345916450\n",
      "Epoch: 2360/20000, Loss: 0.0011149795027450\n",
      "Epoch: 2370/20000, Loss: 0.0010972210438922\n",
      "Epoch: 2380/20000, Loss: 0.0010797010036185\n",
      "Epoch: 2390/20000, Loss: 0.0010626431321725\n",
      "Epoch: 2400/20000, Loss: 0.0010459257755429\n",
      "Epoch: 2410/20000, Loss: 0.0010295162210241\n",
      "Epoch: 2420/20000, Loss: 0.0010133263422176\n",
      "Epoch: 2430/20000, Loss: 0.0009971259860322\n",
      "Epoch: 2440/20000, Loss: 0.0009802978020161\n",
      "Epoch: 2450/20000, Loss: 0.0009634630405344\n",
      "Epoch: 2460/20000, Loss: 0.0009483412140980\n",
      "Epoch: 2470/20000, Loss: 0.0009336971561424\n",
      "Epoch: 2480/20000, Loss: 0.0009194280719385\n",
      "Epoch: 2490/20000, Loss: 0.0009055312839337\n",
      "Epoch: 2500/20000, Loss: 0.0008919764077291\n",
      "Epoch: 2510/20000, Loss: 0.0008787373080850\n",
      "Epoch: 2520/20000, Loss: 0.0008657989674248\n",
      "Epoch: 2530/20000, Loss: 0.0008531507337466\n",
      "Epoch: 2540/20000, Loss: 0.0008407850982621\n",
      "Epoch: 2550/20000, Loss: 0.0008286961819977\n",
      "Epoch: 2560/20000, Loss: 0.0008168780477718\n",
      "Epoch: 2570/20000, Loss: 0.0008053256315179\n",
      "Epoch: 2580/20000, Loss: 0.0007940329960547\n",
      "Epoch: 2590/20000, Loss: 0.0007830943795852\n",
      "Epoch: 2600/20000, Loss: 0.0007727695046924\n",
      "Epoch: 2610/20000, Loss: 0.0007618664531037\n",
      "Epoch: 2620/20000, Loss: 0.0007513428572565\n",
      "Epoch: 2630/20000, Loss: 0.0007412816048600\n",
      "Epoch: 2640/20000, Loss: 0.0007313836249523\n",
      "Epoch: 2650/20000, Loss: 0.0007217233069241\n",
      "Epoch: 2660/20000, Loss: 0.0007122707320377\n",
      "Epoch: 2670/20000, Loss: 0.0007030158303678\n",
      "Epoch: 2680/20000, Loss: 0.0006939540617168\n",
      "Epoch: 2690/20000, Loss: 0.0006850793142803\n",
      "Epoch: 2700/20000, Loss: 0.0006763858837076\n",
      "Epoch: 2710/20000, Loss: 0.0006678681820631\n",
      "Epoch: 2720/20000, Loss: 0.0006595210288651\n",
      "Epoch: 2730/20000, Loss: 0.0006513393018395\n",
      "Epoch: 2740/20000, Loss: 0.0006433182279579\n",
      "Epoch: 2750/20000, Loss: 0.0006354529177770\n",
      "Epoch: 2760/20000, Loss: 0.0006277391221374\n",
      "Epoch: 2770/20000, Loss: 0.0006201717769727\n",
      "Epoch: 2780/20000, Loss: 0.0006127465167083\n",
      "Epoch: 2790/20000, Loss: 0.0006054582190700\n",
      "Epoch: 2800/20000, Loss: 0.0005983005976304\n",
      "Epoch: 2810/20000, Loss: 0.0005912628257647\n",
      "Epoch: 2820/20000, Loss: 0.0005843124235980\n",
      "Epoch: 2830/20000, Loss: 0.0005773341399617\n",
      "Epoch: 2840/20000, Loss: 0.0005705566145480\n",
      "Epoch: 2850/20000, Loss: 0.0005640327581204\n",
      "Epoch: 2860/20000, Loss: 0.0005578062264249\n",
      "Epoch: 2870/20000, Loss: 0.0005507143796422\n",
      "Epoch: 2880/20000, Loss: 0.0005441638641059\n",
      "Epoch: 2890/20000, Loss: 0.0005379167268984\n",
      "Epoch: 2900/20000, Loss: 0.0005318467156030\n",
      "Epoch: 2910/20000, Loss: 0.0005258879973553\n",
      "Epoch: 2920/20000, Loss: 0.0005200254381634\n",
      "Epoch: 2930/20000, Loss: 0.0005142395384610\n",
      "Epoch: 2940/20000, Loss: 0.0005085295415483\n",
      "Epoch: 2950/20000, Loss: 0.0005042147822678\n",
      "Epoch: 2960/20000, Loss: 0.0004973845207132\n",
      "Epoch: 2970/20000, Loss: 0.0004919941420667\n",
      "Epoch: 2980/20000, Loss: 0.0004867077223025\n",
      "Epoch: 2990/20000, Loss: 0.0004814001149498\n",
      "Epoch: 3000/20000, Loss: 0.0004762620956171\n",
      "Epoch: 3010/20000, Loss: 0.0004711938672699\n",
      "Epoch: 3020/20000, Loss: 0.0004662259307224\n",
      "Epoch: 3030/20000, Loss: 0.0004621905100066\n",
      "Epoch: 3040/20000, Loss: 0.0004566955030896\n",
      "Epoch: 3050/20000, Loss: 0.0004517898196355\n",
      "Epoch: 3060/20000, Loss: 0.0004471726715565\n",
      "Epoch: 3070/20000, Loss: 0.0004425198421814\n",
      "Epoch: 3080/20000, Loss: 0.0004379931779113\n",
      "Epoch: 3090/20000, Loss: 0.0004335292032920\n",
      "Epoch: 3100/20000, Loss: 0.0004291397635825\n",
      "Epoch: 3110/20000, Loss: 0.0004250943893567\n",
      "Epoch: 3120/20000, Loss: 0.0004206238954794\n",
      "Epoch: 3130/20000, Loss: 0.0004164662386756\n",
      "Epoch: 3140/20000, Loss: 0.0004122304962948\n",
      "Epoch: 3150/20000, Loss: 0.0004081086663064\n",
      "Epoch: 3160/20000, Loss: 0.0004040504572913\n",
      "Epoch: 3170/20000, Loss: 0.0004000986227766\n",
      "Epoch: 3180/20000, Loss: 0.0003965031646658\n",
      "Epoch: 3190/20000, Loss: 0.0003923002805095\n",
      "Epoch: 3200/20000, Loss: 0.0003884306061082\n",
      "Epoch: 3210/20000, Loss: 0.0003846966719721\n",
      "Epoch: 3220/20000, Loss: 0.0003809271729551\n",
      "Epoch: 3230/20000, Loss: 0.0003773041535169\n",
      "Epoch: 3240/20000, Loss: 0.0003744486602955\n",
      "Epoch: 3250/20000, Loss: 0.0003701100649778\n",
      "Epoch: 3260/20000, Loss: 0.0003665005788207\n",
      "Epoch: 3270/20000, Loss: 0.0003630171704572\n",
      "Epoch: 3280/20000, Loss: 0.0003595402522478\n",
      "Epoch: 3290/20000, Loss: 0.0003561087651178\n",
      "Epoch: 3300/20000, Loss: 0.0003527449152898\n",
      "Epoch: 3310/20000, Loss: 0.0003495232376736\n",
      "Epoch: 3320/20000, Loss: 0.0003465717891231\n",
      "Epoch: 3330/20000, Loss: 0.0003429494099692\n",
      "Epoch: 3340/20000, Loss: 0.0003396480460651\n",
      "Epoch: 3350/20000, Loss: 0.0003364646108821\n",
      "Epoch: 3360/20000, Loss: 0.0003333231143188\n",
      "Epoch: 3370/20000, Loss: 0.0003302023396827\n",
      "Epoch: 3380/20000, Loss: 0.0003271915775258\n",
      "Epoch: 3390/20000, Loss: 0.0003250686277170\n",
      "Epoch: 3400/20000, Loss: 0.0003213247400708\n",
      "Epoch: 3410/20000, Loss: 0.0003181190986652\n",
      "Epoch: 3420/20000, Loss: 0.0003151654673275\n",
      "Epoch: 3430/20000, Loss: 0.0003122609923594\n",
      "Epoch: 3440/20000, Loss: 0.0003093974373769\n",
      "Epoch: 3450/20000, Loss: 0.0003065421478823\n",
      "Epoch: 3460/20000, Loss: 0.0003037285932805\n",
      "Epoch: 3470/20000, Loss: 0.0003009460633621\n",
      "Epoch: 3480/20000, Loss: 0.0002985597238876\n",
      "Epoch: 3490/20000, Loss: 0.0002968813059852\n",
      "Epoch: 3500/20000, Loss: 0.0002933907089755\n",
      "Epoch: 3510/20000, Loss: 0.0002903790737037\n",
      "Epoch: 3520/20000, Loss: 0.0002875576901715\n",
      "Epoch: 3530/20000, Loss: 0.0002849013253581\n",
      "Epoch: 3540/20000, Loss: 0.0002822970272973\n",
      "Epoch: 3550/20000, Loss: 0.0002797130728140\n",
      "Epoch: 3560/20000, Loss: 0.0002771653817035\n",
      "Epoch: 3570/20000, Loss: 0.0002747080288827\n",
      "Epoch: 3580/20000, Loss: 0.0002723250363488\n",
      "Epoch: 3590/20000, Loss: 0.0002697732415982\n",
      "Epoch: 3600/20000, Loss: 0.0002672606788110\n",
      "Epoch: 3610/20000, Loss: 0.0002648712834343\n",
      "Epoch: 3620/20000, Loss: 0.0002624220505822\n",
      "Epoch: 3630/20000, Loss: 0.0002600864972919\n",
      "Epoch: 3640/20000, Loss: 0.0002583953319117\n",
      "Epoch: 3650/20000, Loss: 0.0002555651008151\n",
      "Epoch: 3660/20000, Loss: 0.0002531344071031\n",
      "Epoch: 3670/20000, Loss: 0.0002507930330466\n",
      "Epoch: 3680/20000, Loss: 0.0002485599834472\n",
      "Epoch: 3690/20000, Loss: 0.0002463085402269\n",
      "Epoch: 3700/20000, Loss: 0.0002441076212563\n",
      "Epoch: 3710/20000, Loss: 0.0002422973193461\n",
      "Epoch: 3720/20000, Loss: 0.0002397524658591\n",
      "Epoch: 3730/20000, Loss: 0.0002379862562520\n",
      "Epoch: 3740/20000, Loss: 0.0002354932657909\n",
      "Epoch: 3750/20000, Loss: 0.0002334184828214\n",
      "Epoch: 3760/20000, Loss: 0.0002313127479283\n",
      "Epoch: 3770/20000, Loss: 0.0002292307472089\n",
      "Epoch: 3780/20000, Loss: 0.0002271807752550\n",
      "Epoch: 3790/20000, Loss: 0.0002251519181300\n",
      "Epoch: 3800/20000, Loss: 0.0002231409307569\n",
      "Epoch: 3810/20000, Loss: 0.0002211501123384\n",
      "Epoch: 3820/20000, Loss: 0.0002191807143390\n",
      "Epoch: 3830/20000, Loss: 0.0002173816028517\n",
      "Epoch: 3840/20000, Loss: 0.0002163665340049\n",
      "Epoch: 3850/20000, Loss: 0.0002133812813554\n",
      "Epoch: 3860/20000, Loss: 0.0002116570394719\n",
      "Epoch: 3870/20000, Loss: 0.0002095944801113\n",
      "Epoch: 3880/20000, Loss: 0.0002077304816339\n",
      "Epoch: 3890/20000, Loss: 0.0002058796235360\n",
      "Epoch: 3900/20000, Loss: 0.0002040400722763\n",
      "Epoch: 3910/20000, Loss: 0.0002022189000854\n",
      "Epoch: 3920/20000, Loss: 0.0002004148118431\n",
      "Epoch: 3930/20000, Loss: 0.0001986282150028\n",
      "Epoch: 3940/20000, Loss: 0.0001968569122255\n",
      "Epoch: 3950/20000, Loss: 0.0001951182493940\n",
      "Epoch: 3960/20000, Loss: 0.0001943736424437\n",
      "Epoch: 3970/20000, Loss: 0.0001921733928612\n",
      "Epoch: 3980/20000, Loss: 0.0001901565265143\n",
      "Epoch: 3990/20000, Loss: 0.0001882625801954\n",
      "Epoch: 4000/20000, Loss: 0.0001865977392299\n",
      "Epoch: 4010/20000, Loss: 0.0001848871179391\n",
      "Epoch: 4020/20000, Loss: 0.0001832298730733\n",
      "Epoch: 4030/20000, Loss: 0.0001815908035496\n",
      "Epoch: 4040/20000, Loss: 0.0001799654564820\n",
      "Epoch: 4050/20000, Loss: 0.0001783540210454\n",
      "Epoch: 4060/20000, Loss: 0.0001767550711520\n",
      "Epoch: 4070/20000, Loss: 0.0001751703675836\n",
      "Epoch: 4080/20000, Loss: 0.0001736041449476\n",
      "Epoch: 4090/20000, Loss: 0.0001724020694382\n",
      "Epoch: 4100/20000, Loss: 0.0001706084731268\n",
      "Epoch: 4110/20000, Loss: 0.0001694651582511\n",
      "Epoch: 4120/20000, Loss: 0.0001674549566815\n",
      "Epoch: 4130/20000, Loss: 0.0001660205598455\n",
      "Epoch: 4140/20000, Loss: 0.0001644543954171\n",
      "Epoch: 4150/20000, Loss: 0.0001629747130210\n",
      "Epoch: 4160/20000, Loss: 0.0001615057699382\n",
      "Epoch: 4170/20000, Loss: 0.0001600469986442\n",
      "Epoch: 4180/20000, Loss: 0.0001586016005604\n",
      "Epoch: 4190/20000, Loss: 0.0001571686298121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4200/20000, Loss: 0.0001557479554322\n",
      "Epoch: 4210/20000, Loss: 0.0001543390244478\n",
      "Epoch: 4220/20000, Loss: 0.0001529419969302\n",
      "Epoch: 4230/20000, Loss: 0.0001515608892078\n",
      "Epoch: 4240/20000, Loss: 0.0001506721891928\n",
      "Epoch: 4250/20000, Loss: 0.0001488526322646\n",
      "Epoch: 4260/20000, Loss: 0.0001480113132857\n",
      "Epoch: 4270/20000, Loss: 0.0001463874214096\n",
      "Epoch: 4280/20000, Loss: 0.0001448240509490\n",
      "Epoch: 4290/20000, Loss: 0.0001435165322619\n",
      "Epoch: 4300/20000, Loss: 0.0001422013592673\n",
      "Epoch: 4310/20000, Loss: 0.0001409016986145\n",
      "Epoch: 4320/20000, Loss: 0.0001396164007019\n",
      "Epoch: 4330/20000, Loss: 0.0001383446942782\n",
      "Epoch: 4340/20000, Loss: 0.0001370829995722\n",
      "Epoch: 4350/20000, Loss: 0.0001358320296276\n",
      "Epoch: 4360/20000, Loss: 0.0001345916680293\n",
      "Epoch: 4370/20000, Loss: 0.0001333618565695\n",
      "Epoch: 4380/20000, Loss: 0.0001321425370406\n",
      "Epoch: 4390/20000, Loss: 0.0001309335348196\n",
      "Epoch: 4400/20000, Loss: 0.0001297358976444\n",
      "Epoch: 4410/20000, Loss: 0.0001286527985940\n",
      "Epoch: 4420/20000, Loss: 0.0001308372884523\n",
      "Epoch: 4430/20000, Loss: 0.0001264818711206\n",
      "Epoch: 4440/20000, Loss: 0.0001250772038475\n",
      "Epoch: 4450/20000, Loss: 0.0001240154670086\n",
      "Epoch: 4460/20000, Loss: 0.0001228198525496\n",
      "Epoch: 4470/20000, Loss: 0.0001216413147631\n",
      "Epoch: 4480/20000, Loss: 0.0001205298613058\n",
      "Epoch: 4490/20000, Loss: 0.0001194116121042\n",
      "Epoch: 4500/20000, Loss: 0.0001183080530609\n",
      "Epoch: 4510/20000, Loss: 0.0001172049451270\n",
      "Epoch: 4520/20000, Loss: 0.0001160873216577\n",
      "Epoch: 4530/20000, Loss: 0.0001148933515651\n",
      "Epoch: 4540/20000, Loss: 0.0001136769060395\n",
      "Epoch: 4550/20000, Loss: 0.0001124636037275\n",
      "Epoch: 4560/20000, Loss: 0.0001112821046263\n",
      "Epoch: 4570/20000, Loss: 0.0001101417219616\n",
      "Epoch: 4580/20000, Loss: 0.0001090370424208\n",
      "Epoch: 4590/20000, Loss: 0.0001079707217286\n",
      "Epoch: 4600/20000, Loss: 0.0001081665832317\n",
      "Epoch: 4610/20000, Loss: 0.0001072408485925\n",
      "Epoch: 4620/20000, Loss: 0.0001048718113452\n",
      "Epoch: 4630/20000, Loss: 0.0001040200077114\n",
      "Epoch: 4640/20000, Loss: 0.0001029874983942\n",
      "Epoch: 4650/20000, Loss: 0.0001019137707772\n",
      "Epoch: 4660/20000, Loss: 0.0001009510961012\n",
      "Epoch: 4670/20000, Loss: 0.0000999928743113\n",
      "Epoch: 4680/20000, Loss: 0.0000990506450762\n",
      "Epoch: 4690/20000, Loss: 0.0000981176272035\n",
      "Epoch: 4700/20000, Loss: 0.0000971963017946\n",
      "Epoch: 4710/20000, Loss: 0.0000962847407209\n",
      "Epoch: 4720/20000, Loss: 0.0000953827693593\n",
      "Epoch: 4730/20000, Loss: 0.0000944903076743\n",
      "Epoch: 4740/20000, Loss: 0.0000936071883189\n",
      "Epoch: 4750/20000, Loss: 0.0000927333094296\n",
      "Epoch: 4760/20000, Loss: 0.0000918685109355\n",
      "Epoch: 4770/20000, Loss: 0.0000910143280635\n",
      "Epoch: 4780/20000, Loss: 0.0000903846230358\n",
      "Epoch: 4790/20000, Loss: 0.0000929571542656\n",
      "Epoch: 4800/20000, Loss: 0.0000899599108379\n",
      "Epoch: 4810/20000, Loss: 0.0000880186707946\n",
      "Epoch: 4820/20000, Loss: 0.0000869252180564\n",
      "Epoch: 4830/20000, Loss: 0.0000860834916239\n",
      "Epoch: 4840/20000, Loss: 0.0000853059245856\n",
      "Epoch: 4850/20000, Loss: 0.0000845158283482\n",
      "Epoch: 4860/20000, Loss: 0.0000837300467538\n",
      "Epoch: 4870/20000, Loss: 0.0000829633281683\n",
      "Epoch: 4880/20000, Loss: 0.0000822021829663\n",
      "Epoch: 4890/20000, Loss: 0.0000814504164737\n",
      "Epoch: 4900/20000, Loss: 0.0000807065516710\n",
      "Epoch: 4910/20000, Loss: 0.0000799705740064\n",
      "Epoch: 4920/20000, Loss: 0.0000792424762039\n",
      "Epoch: 4930/20000, Loss: 0.0000785221200204\n",
      "Epoch: 4940/20000, Loss: 0.0000778095563874\n",
      "Epoch: 4950/20000, Loss: 0.0000771045815782\n",
      "Epoch: 4960/20000, Loss: 0.0000764072174206\n",
      "Epoch: 4970/20000, Loss: 0.0000757174057071\n",
      "Epoch: 4980/20000, Loss: 0.0000750385661377\n",
      "Epoch: 4990/20000, Loss: 0.0000752123887651\n",
      "Epoch: 5000/20000, Loss: 0.0000749687751522\n",
      "Epoch: 5010/20000, Loss: 0.0000733593842597\n",
      "Epoch: 5020/20000, Loss: 0.0000725571590010\n",
      "Epoch: 5030/20000, Loss: 0.0000718327428331\n",
      "Epoch: 5040/20000, Loss: 0.0000711484462954\n",
      "Epoch: 5050/20000, Loss: 0.0000704982812749\n",
      "Epoch: 5060/20000, Loss: 0.0000698671210557\n",
      "Epoch: 5070/20000, Loss: 0.0000692461908329\n",
      "Epoch: 5080/20000, Loss: 0.0000686351777404\n",
      "Epoch: 5090/20000, Loss: 0.0000680325319991\n",
      "Epoch: 5100/20000, Loss: 0.0000674359034747\n",
      "Epoch: 5110/20000, Loss: 0.0000668460270390\n",
      "Epoch: 5120/20000, Loss: 0.0000662627207930\n",
      "Epoch: 5130/20000, Loss: 0.0000656858028378\n",
      "Epoch: 5140/20000, Loss: 0.0000651152222417\n",
      "Epoch: 5150/20000, Loss: 0.0000645509571768\n",
      "Epoch: 5160/20000, Loss: 0.0000639928912278\n",
      "Epoch: 5170/20000, Loss: 0.0000634409734630\n",
      "Epoch: 5180/20000, Loss: 0.0000628951456747\n",
      "Epoch: 5190/20000, Loss: 0.0000623553642072\n",
      "Epoch: 5200/20000, Loss: 0.0000618217018200\n",
      "Epoch: 5210/20000, Loss: 0.0000613165102550\n",
      "Epoch: 5220/20000, Loss: 0.0000654743562336\n",
      "Epoch: 5230/20000, Loss: 0.0000625152533758\n",
      "Epoch: 5240/20000, Loss: 0.0000606988905929\n",
      "Epoch: 5250/20000, Loss: 0.0000595957753831\n",
      "Epoch: 5260/20000, Loss: 0.0000588918592257\n",
      "Epoch: 5270/20000, Loss: 0.0000583122855460\n",
      "Epoch: 5280/20000, Loss: 0.0000577872160648\n",
      "Epoch: 5290/20000, Loss: 0.0000572967619519\n",
      "Epoch: 5300/20000, Loss: 0.0000568214709347\n",
      "Epoch: 5310/20000, Loss: 0.0000563487046747\n",
      "Epoch: 5320/20000, Loss: 0.0000558826795896\n",
      "Epoch: 5330/20000, Loss: 0.0000554216203454\n",
      "Epoch: 5340/20000, Loss: 0.0000549657379452\n",
      "Epoch: 5350/20000, Loss: 0.0000545148359379\n",
      "Epoch: 5360/20000, Loss: 0.0000540688270121\n",
      "Epoch: 5370/20000, Loss: 0.0000536277220817\n",
      "Epoch: 5380/20000, Loss: 0.0000531914047315\n",
      "Epoch: 5390/20000, Loss: 0.0000527597585460\n",
      "Epoch: 5400/20000, Loss: 0.0000523328017152\n",
      "Epoch: 5410/20000, Loss: 0.0000519104287378\n",
      "Epoch: 5420/20000, Loss: 0.0000514926141477\n",
      "Epoch: 5430/20000, Loss: 0.0000510799909534\n",
      "Epoch: 5440/20000, Loss: 0.0000507891636516\n",
      "Epoch: 5450/20000, Loss: 0.0000584579574934\n",
      "Epoch: 5460/20000, Loss: 0.0000513511295139\n",
      "Epoch: 5470/20000, Loss: 0.0000499914312968\n",
      "Epoch: 5480/20000, Loss: 0.0000492720246257\n",
      "Epoch: 5490/20000, Loss: 0.0000487592224090\n",
      "Epoch: 5500/20000, Loss: 0.0000483425101265\n",
      "Epoch: 5510/20000, Loss: 0.0000479553891637\n",
      "Epoch: 5520/20000, Loss: 0.0000475740307593\n",
      "Epoch: 5530/20000, Loss: 0.0000472017345601\n",
      "Epoch: 5540/20000, Loss: 0.0000468349971925\n",
      "Epoch: 5550/20000, Loss: 0.0000464718468720\n",
      "Epoch: 5560/20000, Loss: 0.0000461128511233\n",
      "Epoch: 5570/20000, Loss: 0.0000457577152702\n",
      "Epoch: 5580/20000, Loss: 0.0000454062028439\n",
      "Epoch: 5590/20000, Loss: 0.0000450583102065\n",
      "Epoch: 5600/20000, Loss: 0.0000447140155302\n",
      "Epoch: 5610/20000, Loss: 0.0000443731987616\n",
      "Epoch: 5620/20000, Loss: 0.0000440358890046\n",
      "Epoch: 5630/20000, Loss: 0.0000437019953097\n",
      "Epoch: 5640/20000, Loss: 0.0000433714594692\n",
      "Epoch: 5650/20000, Loss: 0.0000430443724326\n",
      "Epoch: 5660/20000, Loss: 0.0000427302038588\n",
      "Epoch: 5670/20000, Loss: 0.0000442851051048\n",
      "Epoch: 5680/20000, Loss: 0.0000447706661362\n",
      "Epoch: 5690/20000, Loss: 0.0000420683427365\n",
      "Epoch: 5700/20000, Loss: 0.0000415095819335\n",
      "Epoch: 5710/20000, Loss: 0.0000411765831814\n",
      "Epoch: 5720/20000, Loss: 0.0000408859559684\n",
      "Epoch: 5730/20000, Loss: 0.0000405796236009\n",
      "Epoch: 5740/20000, Loss: 0.0000402641744586\n",
      "Epoch: 5750/20000, Loss: 0.0000399660384574\n",
      "Epoch: 5760/20000, Loss: 0.0000396745344915\n",
      "Epoch: 5770/20000, Loss: 0.0000393844238715\n",
      "Epoch: 5780/20000, Loss: 0.0000390979985241\n",
      "Epoch: 5790/20000, Loss: 0.0000388143016608\n",
      "Epoch: 5800/20000, Loss: 0.0000385333296435\n",
      "Epoch: 5810/20000, Loss: 0.0000382550315408\n",
      "Epoch: 5820/20000, Loss: 0.0000379793891625\n",
      "Epoch: 5830/20000, Loss: 0.0000377063151973\n",
      "Epoch: 5840/20000, Loss: 0.0000374358132831\n",
      "Epoch: 5850/20000, Loss: 0.0000371678142983\n",
      "Epoch: 5860/20000, Loss: 0.0000369023036910\n",
      "Epoch: 5870/20000, Loss: 0.0000366392268916\n",
      "Epoch: 5880/20000, Loss: 0.0000363787185051\n",
      "Epoch: 5890/20000, Loss: 0.0000361401616829\n",
      "Epoch: 5900/20000, Loss: 0.0000401274846809\n",
      "Epoch: 5910/20000, Loss: 0.0000389237793570\n",
      "Epoch: 5920/20000, Loss: 0.0000364012521459\n",
      "Epoch: 5930/20000, Loss: 0.0000354202456947\n",
      "Epoch: 5940/20000, Loss: 0.0000349767360603\n",
      "Epoch: 5950/20000, Loss: 0.0000346650085703\n",
      "Epoch: 5960/20000, Loss: 0.0000344007421518\n",
      "Epoch: 5970/20000, Loss: 0.0000341587292496\n",
      "Epoch: 5980/20000, Loss: 0.0000339177095157\n",
      "Epoch: 5990/20000, Loss: 0.0000336803932441\n",
      "Epoch: 6000/20000, Loss: 0.0000334471551469\n",
      "Epoch: 6010/20000, Loss: 0.0000332156596414\n",
      "Epoch: 6020/20000, Loss: 0.0000329863687512\n",
      "Epoch: 6030/20000, Loss: 0.0000327590460074\n",
      "Epoch: 6040/20000, Loss: 0.0000325336040987\n",
      "Epoch: 6050/20000, Loss: 0.0000323100284731\n",
      "Epoch: 6060/20000, Loss: 0.0000320882827509\n",
      "Epoch: 6070/20000, Loss: 0.0000318683341902\n",
      "Epoch: 6080/20000, Loss: 0.0000316501718771\n",
      "Epoch: 6090/20000, Loss: 0.0000314337485179\n",
      "Epoch: 6100/20000, Loss: 0.0000312190422846\n",
      "Epoch: 6110/20000, Loss: 0.0000310060459014\n",
      "Epoch: 6120/20000, Loss: 0.0000307951449940\n",
      "Epoch: 6130/20000, Loss: 0.0000306572146656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6140/20000, Loss: 0.0000403884769185\n",
      "Epoch: 6150/20000, Loss: 0.0000306238980556\n",
      "Epoch: 6160/20000, Loss: 0.0000301838936139\n",
      "Epoch: 6170/20000, Loss: 0.0000298122249660\n",
      "Epoch: 6180/20000, Loss: 0.0000295783574984\n",
      "Epoch: 6190/20000, Loss: 0.0000293891371257\n",
      "Epoch: 6200/20000, Loss: 0.0000291920168820\n",
      "Epoch: 6210/20000, Loss: 0.0000289878225885\n",
      "Epoch: 6220/20000, Loss: 0.0000287873099296\n",
      "Epoch: 6230/20000, Loss: 0.0000285937985609\n",
      "Epoch: 6240/20000, Loss: 0.0000284016077785\n",
      "Epoch: 6250/20000, Loss: 0.0000282110104308\n",
      "Epoch: 6260/20000, Loss: 0.0000280218937405\n",
      "Epoch: 6270/20000, Loss: 0.0000278342249658\n",
      "Epoch: 6280/20000, Loss: 0.0000276478695014\n",
      "Epoch: 6290/20000, Loss: 0.0000274628491752\n",
      "Epoch: 6300/20000, Loss: 0.0000272791330644\n",
      "Epoch: 6310/20000, Loss: 0.0000270967411780\n",
      "Epoch: 6320/20000, Loss: 0.0000269156207651\n",
      "Epoch: 6330/20000, Loss: 0.0000267357918347\n",
      "Epoch: 6340/20000, Loss: 0.0000265572198259\n",
      "Epoch: 6350/20000, Loss: 0.0000263799029199\n",
      "Epoch: 6360/20000, Loss: 0.0000262038302026\n",
      "Epoch: 6370/20000, Loss: 0.0000260296910710\n",
      "Epoch: 6380/20000, Loss: 0.0000259835760517\n",
      "Epoch: 6390/20000, Loss: 0.0000353590839950\n",
      "Epoch: 6400/20000, Loss: 0.0000271033532044\n",
      "Epoch: 6410/20000, Loss: 0.0000257882747974\n",
      "Epoch: 6420/20000, Loss: 0.0000252883637586\n",
      "Epoch: 6430/20000, Loss: 0.0000250556568062\n",
      "Epoch: 6440/20000, Loss: 0.0000248675587500\n",
      "Epoch: 6450/20000, Loss: 0.0000246954186878\n",
      "Epoch: 6460/20000, Loss: 0.0000245305272983\n",
      "Epoch: 6470/20000, Loss: 0.0000243651047640\n",
      "Epoch: 6480/20000, Loss: 0.0000242030455411\n",
      "Epoch: 6490/20000, Loss: 0.0000240436947934\n",
      "Epoch: 6500/20000, Loss: 0.0000238851662289\n",
      "Epoch: 6510/20000, Loss: 0.0000237280237343\n",
      "Epoch: 6520/20000, Loss: 0.0000235720362980\n",
      "Epoch: 6530/20000, Loss: 0.0000234172130149\n",
      "Epoch: 6540/20000, Loss: 0.0000232635102293\n",
      "Epoch: 6550/20000, Loss: 0.0000231109825108\n",
      "Epoch: 6560/20000, Loss: 0.0000229595643759\n",
      "Epoch: 6570/20000, Loss: 0.0000228092940233\n",
      "Epoch: 6580/20000, Loss: 0.0000226601132454\n",
      "Epoch: 6590/20000, Loss: 0.0000225120511459\n",
      "Epoch: 6600/20000, Loss: 0.0000223650895350\n",
      "Epoch: 6610/20000, Loss: 0.0000222192611545\n",
      "Epoch: 6620/20000, Loss: 0.0000220764195547\n",
      "Epoch: 6630/20000, Loss: 0.0000222297767323\n",
      "Epoch: 6640/20000, Loss: 0.0000269598513114\n",
      "Epoch: 6650/20000, Loss: 0.0000235272527789\n",
      "Epoch: 6660/20000, Loss: 0.0000219137891690\n",
      "Epoch: 6670/20000, Loss: 0.0000214130268432\n",
      "Epoch: 6680/20000, Loss: 0.0000212414670386\n",
      "Epoch: 6690/20000, Loss: 0.0000211205097003\n",
      "Epoch: 6700/20000, Loss: 0.0000209744866879\n",
      "Epoch: 6710/20000, Loss: 0.0000208311012102\n",
      "Epoch: 6720/20000, Loss: 0.0000206978711503\n",
      "Epoch: 6730/20000, Loss: 0.0000205637061299\n",
      "Epoch: 6740/20000, Loss: 0.0000204319876502\n",
      "Epoch: 6750/20000, Loss: 0.0000203010877158\n",
      "Epoch: 6760/20000, Loss: 0.0000201711263799\n",
      "Epoch: 6770/20000, Loss: 0.0000200421563932\n",
      "Epoch: 6780/20000, Loss: 0.0000199141341000\n",
      "Epoch: 6790/20000, Loss: 0.0000197870431293\n",
      "Epoch: 6800/20000, Loss: 0.0000196608471015\n",
      "Epoch: 6810/20000, Loss: 0.0000195355933101\n",
      "Epoch: 6820/20000, Loss: 0.0000194112144527\n",
      "Epoch: 6830/20000, Loss: 0.0000192877305381\n",
      "Epoch: 6840/20000, Loss: 0.0000191651506611\n",
      "Epoch: 6850/20000, Loss: 0.0000190445825865\n",
      "Epoch: 6860/20000, Loss: 0.0000190882219613\n",
      "Epoch: 6870/20000, Loss: 0.0000278558472928\n",
      "Epoch: 6880/20000, Loss: 0.0000198046691366\n",
      "Epoch: 6890/20000, Loss: 0.0000188408612303\n",
      "Epoch: 6900/20000, Loss: 0.0000185425942618\n",
      "Epoch: 6910/20000, Loss: 0.0000183902575372\n",
      "Epoch: 6920/20000, Loss: 0.0000182545390999\n",
      "Epoch: 6930/20000, Loss: 0.0000181144841918\n",
      "Epoch: 6940/20000, Loss: 0.0000179970538738\n",
      "Epoch: 6950/20000, Loss: 0.0000178847094503\n",
      "Epoch: 6960/20000, Loss: 0.0000177714027814\n",
      "Epoch: 6970/20000, Loss: 0.0000176602006832\n",
      "Epoch: 6980/20000, Loss: 0.0000175496461452\n",
      "Epoch: 6990/20000, Loss: 0.0000174398555828\n",
      "Epoch: 7000/20000, Loss: 0.0000173309017555\n",
      "Epoch: 7010/20000, Loss: 0.0000172227300936\n",
      "Epoch: 7020/20000, Loss: 0.0000171152914845\n",
      "Epoch: 7030/20000, Loss: 0.0000170086132130\n",
      "Epoch: 7040/20000, Loss: 0.0000169026698131\n",
      "Epoch: 7050/20000, Loss: 0.0000167974667420\n",
      "Epoch: 7060/20000, Loss: 0.0000166929858096\n",
      "Epoch: 7070/20000, Loss: 0.0000165892306541\n",
      "Epoch: 7080/20000, Loss: 0.0000164862794918\n",
      "Epoch: 7090/20000, Loss: 0.0000163915756275\n",
      "Epoch: 7100/20000, Loss: 0.0000178040700121\n",
      "Epoch: 7110/20000, Loss: 0.0000178986811079\n",
      "Epoch: 7120/20000, Loss: 0.0000165560159076\n",
      "Epoch: 7130/20000, Loss: 0.0000162596115842\n",
      "Epoch: 7140/20000, Loss: 0.0000160209310707\n",
      "Epoch: 7150/20000, Loss: 0.0000158517341333\n",
      "Epoch: 7160/20000, Loss: 0.0000157160775416\n",
      "Epoch: 7170/20000, Loss: 0.0000156013484229\n",
      "Epoch: 7180/20000, Loss: 0.0000155054040079\n",
      "Epoch: 7190/20000, Loss: 0.0000154101362568\n",
      "Epoch: 7200/20000, Loss: 0.0000153152031999\n",
      "Epoch: 7210/20000, Loss: 0.0000152215598064\n",
      "Epoch: 7220/20000, Loss: 0.0000151285539687\n",
      "Epoch: 7230/20000, Loss: 0.0000150361856868\n",
      "Epoch: 7240/20000, Loss: 0.0000149445177158\n",
      "Epoch: 7250/20000, Loss: 0.0000148535018525\n",
      "Epoch: 7260/20000, Loss: 0.0000147631162690\n",
      "Epoch: 7270/20000, Loss: 0.0000146733646034\n",
      "Epoch: 7280/20000, Loss: 0.0000145842404891\n",
      "Epoch: 7290/20000, Loss: 0.0000144957457451\n",
      "Epoch: 7300/20000, Loss: 0.0000144078721860\n",
      "Epoch: 7310/20000, Loss: 0.0000143206052599\n",
      "Epoch: 7320/20000, Loss: 0.0000142339640661\n",
      "Epoch: 7330/20000, Loss: 0.0000141480350067\n",
      "Epoch: 7340/20000, Loss: 0.0000140798465509\n",
      "Epoch: 7350/20000, Loss: 0.0000186051856872\n",
      "Epoch: 7360/20000, Loss: 0.0000183906140592\n",
      "Epoch: 7370/20000, Loss: 0.0000151979174916\n",
      "Epoch: 7380/20000, Loss: 0.0000142353837873\n",
      "Epoch: 7390/20000, Loss: 0.0000138463074109\n",
      "Epoch: 7400/20000, Loss: 0.0000136290736918\n",
      "Epoch: 7410/20000, Loss: 0.0000135107347887\n",
      "Epoch: 7420/20000, Loss: 0.0000134185029310\n",
      "Epoch: 7430/20000, Loss: 0.0000133330368044\n",
      "Epoch: 7440/20000, Loss: 0.0000132527457026\n",
      "Epoch: 7450/20000, Loss: 0.0000131743418024\n",
      "Epoch: 7460/20000, Loss: 0.0000130961107061\n",
      "Epoch: 7470/20000, Loss: 0.0000130187854666\n",
      "Epoch: 7480/20000, Loss: 0.0000129420432131\n",
      "Epoch: 7490/20000, Loss: 0.0000128659048642\n",
      "Epoch: 7500/20000, Loss: 0.0000127903231260\n",
      "Epoch: 7510/20000, Loss: 0.0000127152952700\n",
      "Epoch: 7520/20000, Loss: 0.0000126408358483\n",
      "Epoch: 7530/20000, Loss: 0.0000125668957480\n",
      "Epoch: 7540/20000, Loss: 0.0000124935240819\n",
      "Epoch: 7550/20000, Loss: 0.0000124206981127\n",
      "Epoch: 7560/20000, Loss: 0.0000123483960124\n",
      "Epoch: 7570/20000, Loss: 0.0000122766414279\n",
      "Epoch: 7580/20000, Loss: 0.0000122054170788\n",
      "Epoch: 7590/20000, Loss: 0.0000121347284221\n",
      "Epoch: 7600/20000, Loss: 0.0000120656332001\n",
      "Epoch: 7610/20000, Loss: 0.0000121321909319\n",
      "Epoch: 7620/20000, Loss: 0.0000219380817725\n",
      "Epoch: 7630/20000, Loss: 0.0000124103562484\n",
      "Epoch: 7640/20000, Loss: 0.0000121242001114\n",
      "Epoch: 7650/20000, Loss: 0.0000119599899335\n",
      "Epoch: 7660/20000, Loss: 0.0000117886638691\n",
      "Epoch: 7670/20000, Loss: 0.0000116336450446\n",
      "Epoch: 7680/20000, Loss: 0.0000115341053970\n",
      "Epoch: 7690/20000, Loss: 0.0000114698796096\n",
      "Epoch: 7700/20000, Loss: 0.0000114009962999\n",
      "Epoch: 7710/20000, Loss: 0.0000113362175398\n",
      "Epoch: 7720/20000, Loss: 0.0000112718325909\n",
      "Epoch: 7730/20000, Loss: 0.0000112086236186\n",
      "Epoch: 7740/20000, Loss: 0.0000111458666652\n",
      "Epoch: 7750/20000, Loss: 0.0000110835580927\n",
      "Epoch: 7760/20000, Loss: 0.0000110217652036\n",
      "Epoch: 7770/20000, Loss: 0.0000109604407044\n",
      "Epoch: 7780/20000, Loss: 0.0000108995836854\n",
      "Epoch: 7790/20000, Loss: 0.0000108391823233\n",
      "Epoch: 7800/20000, Loss: 0.0000107792502604\n",
      "Epoch: 7810/20000, Loss: 0.0000107197729449\n",
      "Epoch: 7820/20000, Loss: 0.0000106607567432\n",
      "Epoch: 7830/20000, Loss: 0.0000106022507680\n",
      "Epoch: 7840/20000, Loss: 0.0000105518020064\n",
      "Epoch: 7850/20000, Loss: 0.0000118979651234\n",
      "Epoch: 7860/20000, Loss: 0.0000114470685730\n",
      "Epoch: 7870/20000, Loss: 0.0000107905825644\n",
      "Epoch: 7880/20000, Loss: 0.0000106217166831\n",
      "Epoch: 7890/20000, Loss: 0.0000104398859548\n",
      "Epoch: 7900/20000, Loss: 0.0000102977619463\n",
      "Epoch: 7910/20000, Loss: 0.0000101835094029\n",
      "Epoch: 7920/20000, Loss: 0.0000101053747130\n",
      "Epoch: 7930/20000, Loss: 0.0000100518309409\n",
      "Epoch: 7940/20000, Loss: 0.0000099966355265\n",
      "Epoch: 7950/20000, Loss: 0.0000099426306406\n",
      "Epoch: 7960/20000, Loss: 0.0000098897553471\n",
      "Epoch: 7970/20000, Loss: 0.0000098374966910\n",
      "Epoch: 7980/20000, Loss: 0.0000097855991044\n",
      "Epoch: 7990/20000, Loss: 0.0000097341380751\n",
      "Epoch: 8000/20000, Loss: 0.0000096831045084\n",
      "Epoch: 8010/20000, Loss: 0.0000096324420156\n",
      "Epoch: 8020/20000, Loss: 0.0000095821778814\n",
      "Epoch: 8030/20000, Loss: 0.0000095323048299\n",
      "Epoch: 8040/20000, Loss: 0.0000094828037618\n",
      "Epoch: 8050/20000, Loss: 0.0000094336746770\n",
      "Epoch: 8060/20000, Loss: 0.0000093849239420\n",
      "Epoch: 8070/20000, Loss: 0.0000093365415523\n",
      "Epoch: 8080/20000, Loss: 0.0000092889986263\n",
      "Epoch: 8090/20000, Loss: 0.0000093104245025\n",
      "Epoch: 8100/20000, Loss: 0.0000194858421310\n",
      "Epoch: 8110/20000, Loss: 0.0000097307747637\n",
      "Epoch: 8120/20000, Loss: 0.0000095617415354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8130/20000, Loss: 0.0000092752743512\n",
      "Epoch: 8140/20000, Loss: 0.0000091152169261\n",
      "Epoch: 8150/20000, Loss: 0.0000090201856437\n",
      "Epoch: 8160/20000, Loss: 0.0000089459817900\n",
      "Epoch: 8170/20000, Loss: 0.0000088847809820\n",
      "Epoch: 8180/20000, Loss: 0.0000088377701104\n",
      "Epoch: 8190/20000, Loss: 0.0000087942717073\n",
      "Epoch: 8200/20000, Loss: 0.0000087496928245\n",
      "Epoch: 8210/20000, Loss: 0.0000087064900072\n",
      "Epoch: 8220/20000, Loss: 0.0000086634499894\n",
      "Epoch: 8230/20000, Loss: 0.0000086208474386\n",
      "Epoch: 8240/20000, Loss: 0.0000085785486590\n",
      "Epoch: 8250/20000, Loss: 0.0000085365663836\n",
      "Epoch: 8260/20000, Loss: 0.0000084948551375\n",
      "Epoch: 8270/20000, Loss: 0.0000084534503912\n",
      "Epoch: 8280/20000, Loss: 0.0000084123248598\n",
      "Epoch: 8290/20000, Loss: 0.0000083714785433\n",
      "Epoch: 8300/20000, Loss: 0.0000083309150796\n",
      "Epoch: 8310/20000, Loss: 0.0000082906062744\n",
      "Epoch: 8320/20000, Loss: 0.0000082505875980\n",
      "Epoch: 8330/20000, Loss: 0.0000082109609139\n",
      "Epoch: 8340/20000, Loss: 0.0000081855750977\n",
      "Epoch: 8350/20000, Loss: 0.0000107953710540\n",
      "Epoch: 8360/20000, Loss: 0.0000121037955978\n",
      "Epoch: 8370/20000, Loss: 0.0000086718746388\n",
      "Epoch: 8380/20000, Loss: 0.0000081561020124\n",
      "Epoch: 8390/20000, Loss: 0.0000080036033978\n",
      "Epoch: 8400/20000, Loss: 0.0000079544879554\n",
      "Epoch: 8410/20000, Loss: 0.0000079256924437\n",
      "Epoch: 8420/20000, Loss: 0.0000078845368989\n",
      "Epoch: 8430/20000, Loss: 0.0000078381735875\n",
      "Epoch: 8440/20000, Loss: 0.0000078003604358\n",
      "Epoch: 8450/20000, Loss: 0.0000077635213529\n",
      "Epoch: 8460/20000, Loss: 0.0000077269023677\n",
      "Epoch: 8470/20000, Loss: 0.0000076907617768\n",
      "Epoch: 8480/20000, Loss: 0.0000076548840298\n",
      "Epoch: 8490/20000, Loss: 0.0000076192095548\n",
      "Epoch: 8500/20000, Loss: 0.0000075837419899\n",
      "Epoch: 8510/20000, Loss: 0.0000075484690569\n",
      "Epoch: 8520/20000, Loss: 0.0000075134094004\n",
      "Epoch: 8530/20000, Loss: 0.0000074785389188\n",
      "Epoch: 8540/20000, Loss: 0.0000074438526099\n",
      "Epoch: 8550/20000, Loss: 0.0000074093723015\n",
      "Epoch: 8560/20000, Loss: 0.0000073750770753\n",
      "Epoch: 8570/20000, Loss: 0.0000073410160439\n",
      "Epoch: 8580/20000, Loss: 0.0000073089613579\n",
      "Epoch: 8590/20000, Loss: 0.0000074918498285\n",
      "Epoch: 8600/20000, Loss: 0.0000171951451193\n",
      "Epoch: 8610/20000, Loss: 0.0000080660738604\n",
      "Epoch: 8620/20000, Loss: 0.0000072121606536\n",
      "Epoch: 8630/20000, Loss: 0.0000071898552960\n",
      "Epoch: 8640/20000, Loss: 0.0000071920958362\n",
      "Epoch: 8650/20000, Loss: 0.0000071341164585\n",
      "Epoch: 8660/20000, Loss: 0.0000070592068369\n",
      "Epoch: 8670/20000, Loss: 0.0000070214487096\n",
      "Epoch: 8680/20000, Loss: 0.0000069905258897\n",
      "Epoch: 8690/20000, Loss: 0.0000069569191510\n",
      "Epoch: 8700/20000, Loss: 0.0000069257566793\n",
      "Epoch: 8710/20000, Loss: 0.0000068946205829\n",
      "Epoch: 8720/20000, Loss: 0.0000068636691140\n",
      "Epoch: 8730/20000, Loss: 0.0000068329982241\n",
      "Epoch: 8740/20000, Loss: 0.0000068025369728\n",
      "Epoch: 8750/20000, Loss: 0.0000067722535277\n",
      "Epoch: 8760/20000, Loss: 0.0000067421683525\n",
      "Epoch: 8770/20000, Loss: 0.0000067122518885\n",
      "Epoch: 8780/20000, Loss: 0.0000066825232352\n",
      "Epoch: 8790/20000, Loss: 0.0000066529610194\n",
      "Epoch: 8800/20000, Loss: 0.0000066236198109\n",
      "Epoch: 8810/20000, Loss: 0.0000065964782152\n",
      "Epoch: 8820/20000, Loss: 0.0000067772316470\n",
      "Epoch: 8830/20000, Loss: 0.0000164116154338\n",
      "Epoch: 8840/20000, Loss: 0.0000068398262556\n",
      "Epoch: 8850/20000, Loss: 0.0000065878489295\n",
      "Epoch: 8860/20000, Loss: 0.0000066562915890\n",
      "Epoch: 8870/20000, Loss: 0.0000065575031840\n",
      "Epoch: 8880/20000, Loss: 0.0000064280143306\n",
      "Epoch: 8890/20000, Loss: 0.0000063780853452\n",
      "Epoch: 8900/20000, Loss: 0.0000063526044869\n",
      "Epoch: 8910/20000, Loss: 0.0000063201305238\n",
      "Epoch: 8920/20000, Loss: 0.0000062928979787\n",
      "Epoch: 8930/20000, Loss: 0.0000062653730311\n",
      "Epoch: 8940/20000, Loss: 0.0000062382400756\n",
      "Epoch: 8950/20000, Loss: 0.0000062113667809\n",
      "Epoch: 8960/20000, Loss: 0.0000061846531025\n",
      "Epoch: 8970/20000, Loss: 0.0000061580849433\n",
      "Epoch: 8980/20000, Loss: 0.0000061316482061\n",
      "Epoch: 8990/20000, Loss: 0.0000061053247009\n",
      "Epoch: 9000/20000, Loss: 0.0000060791312535\n",
      "Epoch: 9010/20000, Loss: 0.0000060530555857\n",
      "Epoch: 9020/20000, Loss: 0.0000060270899667\n",
      "Epoch: 9030/20000, Loss: 0.0000060014140217\n",
      "Epoch: 9040/20000, Loss: 0.0000059889712247\n",
      "Epoch: 9050/20000, Loss: 0.0000080521667769\n",
      "Epoch: 9060/20000, Loss: 0.0000086548816398\n",
      "Epoch: 9070/20000, Loss: 0.0000066382317527\n",
      "Epoch: 9080/20000, Loss: 0.0000062023955252\n",
      "Epoch: 9090/20000, Loss: 0.0000059766994127\n",
      "Epoch: 9100/20000, Loss: 0.0000058819400692\n",
      "Epoch: 9110/20000, Loss: 0.0000058172763602\n",
      "Epoch: 9120/20000, Loss: 0.0000057864958762\n",
      "Epoch: 9130/20000, Loss: 0.0000057609931901\n",
      "Epoch: 9140/20000, Loss: 0.0000057334987105\n",
      "Epoch: 9150/20000, Loss: 0.0000057089332586\n",
      "Epoch: 9160/20000, Loss: 0.0000056844678511\n",
      "Epoch: 9170/20000, Loss: 0.0000056602234508\n",
      "Epoch: 9180/20000, Loss: 0.0000056361868701\n",
      "Epoch: 9190/20000, Loss: 0.0000056122426031\n",
      "Epoch: 9200/20000, Loss: 0.0000055883861023\n",
      "Epoch: 9210/20000, Loss: 0.0000055646119108\n",
      "Epoch: 9220/20000, Loss: 0.0000055409127526\n",
      "Epoch: 9230/20000, Loss: 0.0000055172963584\n",
      "Epoch: 9240/20000, Loss: 0.0000054937504501\n",
      "Epoch: 9250/20000, Loss: 0.0000054702818488\n",
      "Epoch: 9260/20000, Loss: 0.0000054468823691\n",
      "Epoch: 9270/20000, Loss: 0.0000054236934375\n",
      "Epoch: 9280/20000, Loss: 0.0000054244601415\n",
      "Epoch: 9290/20000, Loss: 0.0000121051971291\n",
      "Epoch: 9300/20000, Loss: 0.0000088156139100\n",
      "Epoch: 9310/20000, Loss: 0.0000064718401518\n",
      "Epoch: 9320/20000, Loss: 0.0000055748209888\n",
      "Epoch: 9330/20000, Loss: 0.0000053091916925\n",
      "Epoch: 9340/20000, Loss: 0.0000053019425650\n",
      "Epoch: 9350/20000, Loss: 0.0000052572995628\n",
      "Epoch: 9360/20000, Loss: 0.0000052297295952\n",
      "Epoch: 9370/20000, Loss: 0.0000052074756240\n",
      "Epoch: 9380/20000, Loss: 0.0000051834658734\n",
      "Epoch: 9390/20000, Loss: 0.0000051600559345\n",
      "Epoch: 9400/20000, Loss: 0.0000051378174248\n",
      "Epoch: 9410/20000, Loss: 0.0000051156357586\n",
      "Epoch: 9420/20000, Loss: 0.0000050935850595\n",
      "Epoch: 9430/20000, Loss: 0.0000050716148507\n",
      "Epoch: 9440/20000, Loss: 0.0000050497114898\n",
      "Epoch: 9450/20000, Loss: 0.0000050278717936\n",
      "Epoch: 9460/20000, Loss: 0.0000050060789363\n",
      "Epoch: 9470/20000, Loss: 0.0000049843447414\n",
      "Epoch: 9480/20000, Loss: 0.0000049626582950\n",
      "Epoch: 9490/20000, Loss: 0.0000049410250540\n",
      "Epoch: 9500/20000, Loss: 0.0000049194409257\n",
      "Epoch: 9510/20000, Loss: 0.0000048978999985\n",
      "Epoch: 9520/20000, Loss: 0.0000048764118219\n",
      "Epoch: 9530/20000, Loss: 0.0000048549700296\n",
      "Epoch: 9540/20000, Loss: 0.0000048335773499\n",
      "Epoch: 9550/20000, Loss: 0.0000048128717935\n",
      "Epoch: 9560/20000, Loss: 0.0000049156251407\n",
      "Epoch: 9570/20000, Loss: 0.0000178916725417\n",
      "Epoch: 9580/20000, Loss: 0.0000062929652813\n",
      "Epoch: 9590/20000, Loss: 0.0000053040234889\n",
      "Epoch: 9600/20000, Loss: 0.0000050438316066\n",
      "Epoch: 9610/20000, Loss: 0.0000048388919822\n",
      "Epoch: 9620/20000, Loss: 0.0000047127668950\n",
      "Epoch: 9630/20000, Loss: 0.0000046608670345\n",
      "Epoch: 9640/20000, Loss: 0.0000046331756494\n",
      "Epoch: 9650/20000, Loss: 0.0000046123432185\n",
      "Epoch: 9660/20000, Loss: 0.0000045917026910\n",
      "Epoch: 9670/20000, Loss: 0.0000045702622629\n",
      "Epoch: 9680/20000, Loss: 0.0000045496703933\n",
      "Epoch: 9690/20000, Loss: 0.0000045291776587\n",
      "Epoch: 9700/20000, Loss: 0.0000045087740546\n",
      "Epoch: 9710/20000, Loss: 0.0000044884268391\n",
      "Epoch: 9720/20000, Loss: 0.0000044681369218\n",
      "Epoch: 9730/20000, Loss: 0.0000044478888412\n",
      "Epoch: 9740/20000, Loss: 0.0000044276780500\n",
      "Epoch: 9750/20000, Loss: 0.0000044075140977\n",
      "Epoch: 9760/20000, Loss: 0.0000043873860704\n",
      "Epoch: 9770/20000, Loss: 0.0000043672966967\n",
      "Epoch: 9780/20000, Loss: 0.0000043472450670\n",
      "Epoch: 9790/20000, Loss: 0.0000043272307266\n",
      "Epoch: 9800/20000, Loss: 0.0000043072463995\n",
      "Epoch: 9810/20000, Loss: 0.0000042873148232\n",
      "Epoch: 9820/20000, Loss: 0.0000042681708692\n",
      "Epoch: 9830/20000, Loss: 0.0000043803338485\n",
      "Epoch: 9840/20000, Loss: 0.0000175186705746\n",
      "Epoch: 9850/20000, Loss: 0.0000054542342696\n",
      "Epoch: 9860/20000, Loss: 0.0000045708952712\n",
      "Epoch: 9870/20000, Loss: 0.0000043448890210\n",
      "Epoch: 9880/20000, Loss: 0.0000042417646000\n",
      "Epoch: 9890/20000, Loss: 0.0000041636253627\n",
      "Epoch: 9900/20000, Loss: 0.0000041228349801\n",
      "Epoch: 9910/20000, Loss: 0.0000041017751755\n",
      "Epoch: 9920/20000, Loss: 0.0000040825379983\n",
      "Epoch: 9930/20000, Loss: 0.0000040613913370\n",
      "Epoch: 9940/20000, Loss: 0.0000040418058234\n",
      "Epoch: 9950/20000, Loss: 0.0000040226718738\n",
      "Epoch: 9960/20000, Loss: 0.0000040034965423\n",
      "Epoch: 9970/20000, Loss: 0.0000039844376261\n",
      "Epoch: 9980/20000, Loss: 0.0000039654441935\n",
      "Epoch: 9990/20000, Loss: 0.0000039464871406\n",
      "Epoch: 10000/20000, Loss: 0.0000039275764721\n",
      "Epoch: 10010/20000, Loss: 0.0000039087053665\n",
      "Epoch: 10020/20000, Loss: 0.0000038898806451\n",
      "Epoch: 10030/20000, Loss: 0.0000038710882109\n",
      "Epoch: 10040/20000, Loss: 0.0000038523330659\n",
      "Epoch: 10050/20000, Loss: 0.0000038336124817\n",
      "Epoch: 10060/20000, Loss: 0.0000038149401007\n",
      "Epoch: 10070/20000, Loss: 0.0000037963545765\n",
      "Epoch: 10080/20000, Loss: 0.0000037808952129\n",
      "Epoch: 10090/20000, Loss: 0.0000041434823288\n",
      "Epoch: 10100/20000, Loss: 0.0000104101409306\n",
      "Epoch: 10110/20000, Loss: 0.0000055566815718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10120/20000, Loss: 0.0000039527503759\n",
      "Epoch: 10130/20000, Loss: 0.0000037001113924\n",
      "Epoch: 10140/20000, Loss: 0.0000036982805796\n",
      "Epoch: 10150/20000, Loss: 0.0000036891647142\n",
      "Epoch: 10160/20000, Loss: 0.0000036445680962\n",
      "Epoch: 10170/20000, Loss: 0.0000036212911709\n",
      "Epoch: 10180/20000, Loss: 0.0000036035708035\n",
      "Epoch: 10190/20000, Loss: 0.0000035843208934\n",
      "Epoch: 10200/20000, Loss: 0.0000035660530102\n",
      "Epoch: 10210/20000, Loss: 0.0000035482078147\n",
      "Epoch: 10220/20000, Loss: 0.0000035303571622\n",
      "Epoch: 10230/20000, Loss: 0.0000035125697195\n",
      "Epoch: 10240/20000, Loss: 0.0000034948513985\n",
      "Epoch: 10250/20000, Loss: 0.0000034771778701\n",
      "Epoch: 10260/20000, Loss: 0.0000034595564102\n",
      "Epoch: 10270/20000, Loss: 0.0000034419781514\n",
      "Epoch: 10280/20000, Loss: 0.0000034244405924\n",
      "Epoch: 10290/20000, Loss: 0.0000034069526009\n",
      "Epoch: 10300/20000, Loss: 0.0000033895039451\n",
      "Epoch: 10310/20000, Loss: 0.0000033722196804\n",
      "Epoch: 10320/20000, Loss: 0.0000033727508253\n",
      "Epoch: 10330/20000, Loss: 0.0000077800641520\n",
      "Epoch: 10340/20000, Loss: 0.0000089826780822\n",
      "Epoch: 10350/20000, Loss: 0.0000050308908612\n",
      "Epoch: 10360/20000, Loss: 0.0000039564624785\n",
      "Epoch: 10370/20000, Loss: 0.0000035172786284\n",
      "Epoch: 10380/20000, Loss: 0.0000033336091292\n",
      "Epoch: 10390/20000, Loss: 0.0000032690716125\n",
      "Epoch: 10400/20000, Loss: 0.0000032359225770\n",
      "Epoch: 10410/20000, Loss: 0.0000032117520732\n",
      "Epoch: 10420/20000, Loss: 0.0000031933282116\n",
      "Epoch: 10430/20000, Loss: 0.0000031768659028\n",
      "Epoch: 10440/20000, Loss: 0.0000031599108752\n",
      "Epoch: 10450/20000, Loss: 0.0000031433348795\n",
      "Epoch: 10460/20000, Loss: 0.0000031268521070\n",
      "Epoch: 10470/20000, Loss: 0.0000031104491427\n",
      "Epoch: 10480/20000, Loss: 0.0000030940941542\n",
      "Epoch: 10490/20000, Loss: 0.0000030777903248\n",
      "Epoch: 10500/20000, Loss: 0.0000030615465221\n",
      "Epoch: 10510/20000, Loss: 0.0000030453534237\n",
      "Epoch: 10520/20000, Loss: 0.0000030292042084\n",
      "Epoch: 10530/20000, Loss: 0.0000030131102449\n",
      "Epoch: 10540/20000, Loss: 0.0000029970653941\n",
      "Epoch: 10550/20000, Loss: 0.0000029810676097\n",
      "Epoch: 10560/20000, Loss: 0.0000029651180284\n",
      "Epoch: 10570/20000, Loss: 0.0000029492543945\n",
      "Epoch: 10580/20000, Loss: 0.0000029349885153\n",
      "Epoch: 10590/20000, Loss: 0.0000030930802950\n",
      "Epoch: 10600/20000, Loss: 0.0000134157426146\n",
      "Epoch: 10610/20000, Loss: 0.0000033729170354\n",
      "Epoch: 10620/20000, Loss: 0.0000032238397125\n",
      "Epoch: 10630/20000, Loss: 0.0000030997605336\n",
      "Epoch: 10640/20000, Loss: 0.0000029725242712\n",
      "Epoch: 10650/20000, Loss: 0.0000028659062536\n",
      "Epoch: 10660/20000, Loss: 0.0000028185493193\n",
      "Epoch: 10670/20000, Loss: 0.0000028061849662\n",
      "Epoch: 10680/20000, Loss: 0.0000027859730380\n",
      "Epoch: 10690/20000, Loss: 0.0000027706926176\n",
      "Epoch: 10700/20000, Loss: 0.0000027547857826\n",
      "Epoch: 10710/20000, Loss: 0.0000027398064049\n",
      "Epoch: 10720/20000, Loss: 0.0000027248700007\n",
      "Epoch: 10730/20000, Loss: 0.0000027099747513\n",
      "Epoch: 10740/20000, Loss: 0.0000026951520340\n",
      "Epoch: 10750/20000, Loss: 0.0000026803925266\n",
      "Epoch: 10760/20000, Loss: 0.0000026656932732\n",
      "Epoch: 10770/20000, Loss: 0.0000026510520001\n",
      "Epoch: 10780/20000, Loss: 0.0000026364662062\n",
      "Epoch: 10790/20000, Loss: 0.0000026219374831\n",
      "Epoch: 10800/20000, Loss: 0.0000026074708330\n",
      "Epoch: 10810/20000, Loss: 0.0000025938454655\n",
      "Epoch: 10820/20000, Loss: 0.0000026682969292\n",
      "Epoch: 10830/20000, Loss: 0.0000127758257804\n",
      "Epoch: 10840/20000, Loss: 0.0000037372010411\n",
      "Epoch: 10850/20000, Loss: 0.0000034619320104\n",
      "Epoch: 10860/20000, Loss: 0.0000029680547868\n",
      "Epoch: 10870/20000, Loss: 0.0000026810414511\n",
      "Epoch: 10880/20000, Loss: 0.0000025380400075\n",
      "Epoch: 10890/20000, Loss: 0.0000024901432880\n",
      "Epoch: 10900/20000, Loss: 0.0000024786788799\n",
      "Epoch: 10910/20000, Loss: 0.0000024605756153\n",
      "Epoch: 10920/20000, Loss: 0.0000024459984616\n",
      "Epoch: 10930/20000, Loss: 0.0000024318244414\n",
      "Epoch: 10940/20000, Loss: 0.0000024182279503\n",
      "Epoch: 10950/20000, Loss: 0.0000024046601084\n",
      "Epoch: 10960/20000, Loss: 0.0000023912382403\n",
      "Epoch: 10970/20000, Loss: 0.0000023778970899\n",
      "Epoch: 10980/20000, Loss: 0.0000023646173304\n",
      "Epoch: 10990/20000, Loss: 0.0000023513994165\n",
      "Epoch: 11000/20000, Loss: 0.0000023382322070\n",
      "Epoch: 11010/20000, Loss: 0.0000023251300263\n",
      "Epoch: 11020/20000, Loss: 0.0000023120894639\n",
      "Epoch: 11030/20000, Loss: 0.0000022991002879\n",
      "Epoch: 11040/20000, Loss: 0.0000022861702291\n",
      "Epoch: 11050/20000, Loss: 0.0000022736214760\n",
      "Epoch: 11060/20000, Loss: 0.0000023041282020\n",
      "Epoch: 11070/20000, Loss: 0.0000100289398688\n",
      "Epoch: 11080/20000, Loss: 0.0000052915270317\n",
      "Epoch: 11090/20000, Loss: 0.0000035326922898\n",
      "Epoch: 11100/20000, Loss: 0.0000027524840789\n",
      "Epoch: 11110/20000, Loss: 0.0000023801244424\n",
      "Epoch: 11120/20000, Loss: 0.0000022454764803\n",
      "Epoch: 11130/20000, Loss: 0.0000021942551029\n",
      "Epoch: 11140/20000, Loss: 0.0000021694120278\n",
      "Epoch: 11150/20000, Loss: 0.0000021570729132\n",
      "Epoch: 11160/20000, Loss: 0.0000021439138891\n",
      "Epoch: 11170/20000, Loss: 0.0000021308355826\n",
      "Epoch: 11180/20000, Loss: 0.0000021188357096\n",
      "Epoch: 11190/20000, Loss: 0.0000021068012757\n",
      "Epoch: 11200/20000, Loss: 0.0000020949271402\n",
      "Epoch: 11210/20000, Loss: 0.0000020831469101\n",
      "Epoch: 11220/20000, Loss: 0.0000020714253424\n",
      "Epoch: 11230/20000, Loss: 0.0000020597669845\n",
      "Epoch: 11240/20000, Loss: 0.0000020481609226\n",
      "Epoch: 11250/20000, Loss: 0.0000020366196622\n",
      "Epoch: 11260/20000, Loss: 0.0000020251384285\n",
      "Epoch: 11270/20000, Loss: 0.0000020137060801\n",
      "Epoch: 11280/20000, Loss: 0.0000020023330762\n",
      "Epoch: 11290/20000, Loss: 0.0000019910160063\n",
      "Epoch: 11300/20000, Loss: 0.0000019797887489\n",
      "Epoch: 11310/20000, Loss: 0.0000019711194454\n",
      "Epoch: 11320/20000, Loss: 0.0000023825455173\n",
      "Epoch: 11330/20000, Loss: 0.0000077807962953\n",
      "Epoch: 11340/20000, Loss: 0.0000044028893171\n",
      "Epoch: 11350/20000, Loss: 0.0000026958873605\n",
      "Epoch: 11360/20000, Loss: 0.0000022262418042\n",
      "Epoch: 11370/20000, Loss: 0.0000019904869077\n",
      "Epoch: 11380/20000, Loss: 0.0000019050072524\n",
      "Epoch: 11390/20000, Loss: 0.0000018906413288\n",
      "Epoch: 11400/20000, Loss: 0.0000018813176439\n",
      "Epoch: 11410/20000, Loss: 0.0000018665863308\n",
      "Epoch: 11420/20000, Loss: 0.0000018560180024\n",
      "Epoch: 11430/20000, Loss: 0.0000018451552251\n",
      "Epoch: 11440/20000, Loss: 0.0000018348023332\n",
      "Epoch: 11450/20000, Loss: 0.0000018244342073\n",
      "Epoch: 11460/20000, Loss: 0.0000018141879536\n",
      "Epoch: 11470/20000, Loss: 0.0000018040104806\n",
      "Epoch: 11480/20000, Loss: 0.0000017938938299\n",
      "Epoch: 11490/20000, Loss: 0.0000017838277699\n",
      "Epoch: 11500/20000, Loss: 0.0000017738217366\n",
      "Epoch: 11510/20000, Loss: 0.0000017638742520\n",
      "Epoch: 11520/20000, Loss: 0.0000017539771306\n",
      "Epoch: 11530/20000, Loss: 0.0000017441311684\n",
      "Epoch: 11540/20000, Loss: 0.0000017343412537\n",
      "Epoch: 11550/20000, Loss: 0.0000017246632069\n",
      "Epoch: 11560/20000, Loss: 0.0000017198046862\n",
      "Epoch: 11570/20000, Loss: 0.0000024745277187\n",
      "Epoch: 11580/20000, Loss: 0.0000031240899716\n",
      "Epoch: 11590/20000, Loss: 0.0000037088345834\n",
      "Epoch: 11600/20000, Loss: 0.0000025287915832\n",
      "Epoch: 11610/20000, Loss: 0.0000019789290491\n",
      "Epoch: 11620/20000, Loss: 0.0000017293560859\n",
      "Epoch: 11630/20000, Loss: 0.0000016573169432\n",
      "Epoch: 11640/20000, Loss: 0.0000016504735640\n",
      "Epoch: 11650/20000, Loss: 0.0000016395990770\n",
      "Epoch: 11660/20000, Loss: 0.0000016267698584\n",
      "Epoch: 11670/20000, Loss: 0.0000016181168121\n",
      "Epoch: 11680/20000, Loss: 0.0000016086269170\n",
      "Epoch: 11690/20000, Loss: 0.0000015996671436\n",
      "Epoch: 11700/20000, Loss: 0.0000015907960460\n",
      "Epoch: 11710/20000, Loss: 0.0000015819603050\n",
      "Epoch: 11720/20000, Loss: 0.0000015731893654\n",
      "Epoch: 11730/20000, Loss: 0.0000015644837958\n",
      "Epoch: 11740/20000, Loss: 0.0000015558246105\n",
      "Epoch: 11750/20000, Loss: 0.0000015472185169\n",
      "Epoch: 11760/20000, Loss: 0.0000015386642644\n",
      "Epoch: 11770/20000, Loss: 0.0000015301540088\n",
      "Epoch: 11780/20000, Loss: 0.0000015216940028\n",
      "Epoch: 11790/20000, Loss: 0.0000015133516627\n",
      "Epoch: 11800/20000, Loss: 0.0000015093060028\n",
      "Epoch: 11810/20000, Loss: 0.0000020732372832\n",
      "Epoch: 11820/20000, Loss: 0.0000051965103012\n",
      "Epoch: 11830/20000, Loss: 0.0000036415144677\n",
      "Epoch: 11840/20000, Loss: 0.0000019358092231\n",
      "Epoch: 11850/20000, Loss: 0.0000015523252159\n",
      "Epoch: 11860/20000, Loss: 0.0000014931144960\n",
      "Epoch: 11870/20000, Loss: 0.0000014887471025\n",
      "Epoch: 11880/20000, Loss: 0.0000014566597883\n",
      "Epoch: 11890/20000, Loss: 0.0000014388656382\n",
      "Epoch: 11900/20000, Loss: 0.0000014307369156\n",
      "Epoch: 11910/20000, Loss: 0.0000014213765098\n",
      "Epoch: 11920/20000, Loss: 0.0000014133047443\n",
      "Epoch: 11930/20000, Loss: 0.0000014056022337\n",
      "Epoch: 11940/20000, Loss: 0.0000013979125697\n",
      "Epoch: 11950/20000, Loss: 0.0000013902831597\n",
      "Epoch: 11960/20000, Loss: 0.0000013827161638\n",
      "Epoch: 11970/20000, Loss: 0.0000013752056702\n",
      "Epoch: 11980/20000, Loss: 0.0000013677370134\n",
      "Epoch: 11990/20000, Loss: 0.0000013603159914\n",
      "Epoch: 12000/20000, Loss: 0.0000013529385114\n",
      "Epoch: 12010/20000, Loss: 0.0000013455988892\n",
      "Epoch: 12020/20000, Loss: 0.0000013383037185\n",
      "Epoch: 12030/20000, Loss: 0.0000013312252349\n",
      "Epoch: 12040/20000, Loss: 0.0000013447623814\n",
      "Epoch: 12050/20000, Loss: 0.0000054586362239\n",
      "Epoch: 12060/20000, Loss: 0.0000066108214014\n",
      "Epoch: 12070/20000, Loss: 0.0000024223384116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12080/20000, Loss: 0.0000016673061509\n",
      "Epoch: 12090/20000, Loss: 0.0000014498327801\n",
      "Epoch: 12100/20000, Loss: 0.0000013209836425\n",
      "Epoch: 12110/20000, Loss: 0.0000012830339529\n",
      "Epoch: 12120/20000, Loss: 0.0000012780637917\n",
      "Epoch: 12130/20000, Loss: 0.0000012690828726\n",
      "Epoch: 12140/20000, Loss: 0.0000012594273358\n",
      "Epoch: 12150/20000, Loss: 0.0000012529264950\n",
      "Epoch: 12160/20000, Loss: 0.0000012458050378\n",
      "Epoch: 12170/20000, Loss: 0.0000012391938071\n",
      "Epoch: 12180/20000, Loss: 0.0000012325581338\n",
      "Epoch: 12190/20000, Loss: 0.0000012259976074\n",
      "Epoch: 12200/20000, Loss: 0.0000012194919918\n",
      "Epoch: 12210/20000, Loss: 0.0000012130292362\n",
      "Epoch: 12220/20000, Loss: 0.0000012066033150\n",
      "Epoch: 12230/20000, Loss: 0.0000012002160474\n",
      "Epoch: 12240/20000, Loss: 0.0000011938642501\n",
      "Epoch: 12250/20000, Loss: 0.0000011875455357\n",
      "Epoch: 12260/20000, Loss: 0.0000011812628600\n",
      "Epoch: 12270/20000, Loss: 0.0000011750149724\n",
      "Epoch: 12280/20000, Loss: 0.0000011688208588\n",
      "Epoch: 12290/20000, Loss: 0.0000011639813238\n",
      "Epoch: 12300/20000, Loss: 0.0000013511496491\n",
      "Epoch: 12310/20000, Loss: 0.0000126613358589\n",
      "Epoch: 12320/20000, Loss: 0.0000022142000944\n",
      "Epoch: 12330/20000, Loss: 0.0000013102251160\n",
      "Epoch: 12340/20000, Loss: 0.0000011439715308\n",
      "Epoch: 12350/20000, Loss: 0.0000011672623259\n",
      "Epoch: 12360/20000, Loss: 0.0000011673459994\n",
      "Epoch: 12370/20000, Loss: 0.0000011394772628\n",
      "Epoch: 12380/20000, Loss: 0.0000011162529745\n",
      "Epoch: 12390/20000, Loss: 0.0000011091569831\n",
      "Epoch: 12400/20000, Loss: 0.0000011023063280\n",
      "Epoch: 12410/20000, Loss: 0.0000010961664429\n",
      "Epoch: 12420/20000, Loss: 0.0000010902491567\n",
      "Epoch: 12430/20000, Loss: 0.0000010845737961\n",
      "Epoch: 12440/20000, Loss: 0.0000010789137832\n",
      "Epoch: 12450/20000, Loss: 0.0000010733123190\n",
      "Epoch: 12460/20000, Loss: 0.0000010677596265\n",
      "Epoch: 12470/20000, Loss: 0.0000010622353557\n",
      "Epoch: 12480/20000, Loss: 0.0000010567462141\n",
      "Epoch: 12490/20000, Loss: 0.0000010512845847\n",
      "Epoch: 12500/20000, Loss: 0.0000010458546740\n",
      "Epoch: 12510/20000, Loss: 0.0000010404540944\n",
      "Epoch: 12520/20000, Loss: 0.0000010350875073\n",
      "Epoch: 12530/20000, Loss: 0.0000010298117559\n",
      "Epoch: 12540/20000, Loss: 0.0000010294453432\n",
      "Epoch: 12550/20000, Loss: 0.0000017772248384\n",
      "Epoch: 12560/20000, Loss: 0.0000027181290534\n",
      "Epoch: 12570/20000, Loss: 0.0000031544234389\n",
      "Epoch: 12580/20000, Loss: 0.0000018132174091\n",
      "Epoch: 12590/20000, Loss: 0.0000012830387277\n",
      "Epoch: 12600/20000, Loss: 0.0000010579379932\n",
      "Epoch: 12610/20000, Loss: 0.0000010004438309\n",
      "Epoch: 12620/20000, Loss: 0.0000009973275610\n",
      "Epoch: 12630/20000, Loss: 0.0000009855015151\n",
      "Epoch: 12640/20000, Loss: 0.0000009778311778\n",
      "Epoch: 12650/20000, Loss: 0.0000009727858696\n",
      "Epoch: 12660/20000, Loss: 0.0000009674862440\n",
      "Epoch: 12670/20000, Loss: 0.0000009623944379\n",
      "Epoch: 12680/20000, Loss: 0.0000009574914657\n",
      "Epoch: 12690/20000, Loss: 0.0000009526274880\n",
      "Epoch: 12700/20000, Loss: 0.0000009478038123\n",
      "Epoch: 12710/20000, Loss: 0.0000009430089563\n",
      "Epoch: 12720/20000, Loss: 0.0000009382426356\n",
      "Epoch: 12730/20000, Loss: 0.0000009335042819\n",
      "Epoch: 12740/20000, Loss: 0.0000009287998637\n",
      "Epoch: 12750/20000, Loss: 0.0000009241131238\n",
      "Epoch: 12760/20000, Loss: 0.0000009194514519\n",
      "Epoch: 12770/20000, Loss: 0.0000009148154732\n",
      "Epoch: 12780/20000, Loss: 0.0000009102191711\n",
      "Epoch: 12790/20000, Loss: 0.0000009079230949\n",
      "Epoch: 12800/20000, Loss: 0.0000015042152199\n",
      "Epoch: 12810/20000, Loss: 0.0000030730525395\n",
      "Epoch: 12820/20000, Loss: 0.0000025723911676\n",
      "Epoch: 12830/20000, Loss: 0.0000013822718756\n",
      "Epoch: 12840/20000, Loss: 0.0000009032091839\n",
      "Epoch: 12850/20000, Loss: 0.0000009267519090\n",
      "Epoch: 12860/20000, Loss: 0.0000008953775819\n",
      "Epoch: 12870/20000, Loss: 0.0000008761287518\n",
      "Epoch: 12880/20000, Loss: 0.0000008732559991\n",
      "Epoch: 12890/20000, Loss: 0.0000008685631201\n",
      "Epoch: 12900/20000, Loss: 0.0000008627370107\n",
      "Epoch: 12910/20000, Loss: 0.0000008576784580\n",
      "Epoch: 12920/20000, Loss: 0.0000008534087783\n",
      "Epoch: 12930/20000, Loss: 0.0000008491085168\n",
      "Epoch: 12940/20000, Loss: 0.0000008449130178\n",
      "Epoch: 12950/20000, Loss: 0.0000008407461110\n",
      "Epoch: 12960/20000, Loss: 0.0000008366123438\n",
      "Epoch: 12970/20000, Loss: 0.0000008325038152\n",
      "Epoch: 12980/20000, Loss: 0.0000008284241630\n",
      "Epoch: 12990/20000, Loss: 0.0000008243709431\n",
      "Epoch: 13000/20000, Loss: 0.0000008203365951\n",
      "Epoch: 13010/20000, Loss: 0.0000008163232224\n",
      "Epoch: 13020/20000, Loss: 0.0000008123308248\n",
      "Epoch: 13030/20000, Loss: 0.0000008083601983\n",
      "Epoch: 13040/20000, Loss: 0.0000008044102628\n",
      "Epoch: 13050/20000, Loss: 0.0000008004811320\n",
      "Epoch: 13060/20000, Loss: 0.0000007965709301\n",
      "Epoch: 13070/20000, Loss: 0.0000007929461958\n",
      "Epoch: 13080/20000, Loss: 0.0000008258356274\n",
      "Epoch: 13090/20000, Loss: 0.0000080761346908\n",
      "Epoch: 13100/20000, Loss: 0.0000045735428102\n",
      "Epoch: 13110/20000, Loss: 0.0000022175756840\n",
      "Epoch: 13120/20000, Loss: 0.0000013638896235\n",
      "Epoch: 13130/20000, Loss: 0.0000009545744888\n",
      "Epoch: 13140/20000, Loss: 0.0000008261940252\n",
      "Epoch: 13150/20000, Loss: 0.0000007883816693\n",
      "Epoch: 13160/20000, Loss: 0.0000007683231047\n",
      "Epoch: 13170/20000, Loss: 0.0000007612392778\n",
      "Epoch: 13180/20000, Loss: 0.0000007570908451\n",
      "Epoch: 13190/20000, Loss: 0.0000007522179430\n",
      "Epoch: 13200/20000, Loss: 0.0000007485714377\n",
      "Epoch: 13210/20000, Loss: 0.0000007448230122\n",
      "Epoch: 13220/20000, Loss: 0.0000007412532455\n",
      "Epoch: 13230/20000, Loss: 0.0000007376948474\n",
      "Epoch: 13240/20000, Loss: 0.0000007341760693\n",
      "Epoch: 13250/20000, Loss: 0.0000007306833254\n",
      "Epoch: 13260/20000, Loss: 0.0000007272132621\n",
      "Epoch: 13270/20000, Loss: 0.0000007237682667\n",
      "Epoch: 13280/20000, Loss: 0.0000007203391306\n",
      "Epoch: 13290/20000, Loss: 0.0000007169323908\n",
      "Epoch: 13300/20000, Loss: 0.0000007135399187\n",
      "Epoch: 13310/20000, Loss: 0.0000007101686492\n",
      "Epoch: 13320/20000, Loss: 0.0000007068225614\n",
      "Epoch: 13330/20000, Loss: 0.0000007038784702\n",
      "Epoch: 13340/20000, Loss: 0.0000007361757071\n",
      "Epoch: 13350/20000, Loss: 0.0000059371259340\n",
      "Epoch: 13360/20000, Loss: 0.0000052019331633\n",
      "Epoch: 13370/20000, Loss: 0.0000015195555534\n",
      "Epoch: 13380/20000, Loss: 0.0000007965942359\n",
      "Epoch: 13390/20000, Loss: 0.0000007011420280\n",
      "Epoch: 13400/20000, Loss: 0.0000007149936891\n",
      "Epoch: 13410/20000, Loss: 0.0000007066121839\n",
      "Epoch: 13420/20000, Loss: 0.0000006820743579\n",
      "Epoch: 13430/20000, Loss: 0.0000006771030598\n",
      "Epoch: 13440/20000, Loss: 0.0000006723954016\n",
      "Epoch: 13450/20000, Loss: 0.0000006689560337\n",
      "Epoch: 13460/20000, Loss: 0.0000006655382094\n",
      "Epoch: 13470/20000, Loss: 0.0000006624568982\n",
      "Epoch: 13480/20000, Loss: 0.0000006593740522\n",
      "Epoch: 13490/20000, Loss: 0.0000006563191164\n",
      "Epoch: 13500/20000, Loss: 0.0000006533001056\n",
      "Epoch: 13510/20000, Loss: 0.0000006503005920\n",
      "Epoch: 13520/20000, Loss: 0.0000006473194958\n",
      "Epoch: 13530/20000, Loss: 0.0000006443607390\n",
      "Epoch: 13540/20000, Loss: 0.0000006414202858\n",
      "Epoch: 13550/20000, Loss: 0.0000006384904054\n",
      "Epoch: 13560/20000, Loss: 0.0000006356037261\n",
      "Epoch: 13570/20000, Loss: 0.0000006338896696\n",
      "Epoch: 13580/20000, Loss: 0.0000007564520956\n",
      "Epoch: 13590/20000, Loss: 0.0000117119725473\n",
      "Epoch: 13600/20000, Loss: 0.0000013346631249\n",
      "Epoch: 13610/20000, Loss: 0.0000013902773617\n",
      "Epoch: 13620/20000, Loss: 0.0000010259876717\n",
      "Epoch: 13630/20000, Loss: 0.0000007790779364\n",
      "Epoch: 13640/20000, Loss: 0.0000006520371016\n",
      "Epoch: 13650/20000, Loss: 0.0000006214852419\n",
      "Epoch: 13660/20000, Loss: 0.0000006190106205\n",
      "Epoch: 13670/20000, Loss: 0.0000006096095717\n",
      "Epoch: 13680/20000, Loss: 0.0000006066233027\n",
      "Epoch: 13690/20000, Loss: 0.0000006029803785\n",
      "Epoch: 13700/20000, Loss: 0.0000006002953228\n",
      "Epoch: 13710/20000, Loss: 0.0000005975904287\n",
      "Epoch: 13720/20000, Loss: 0.0000005948861599\n",
      "Epoch: 13730/20000, Loss: 0.0000005922387345\n",
      "Epoch: 13740/20000, Loss: 0.0000005896168318\n",
      "Epoch: 13750/20000, Loss: 0.0000005870110158\n",
      "Epoch: 13760/20000, Loss: 0.0000005844216844\n",
      "Epoch: 13770/20000, Loss: 0.0000005818519071\n",
      "Epoch: 13780/20000, Loss: 0.0000005792946922\n",
      "Epoch: 13790/20000, Loss: 0.0000005767458333\n",
      "Epoch: 13800/20000, Loss: 0.0000005742293752\n",
      "Epoch: 13810/20000, Loss: 0.0000005726977292\n",
      "Epoch: 13820/20000, Loss: 0.0000007021819215\n",
      "Epoch: 13830/20000, Loss: 0.0000131179467644\n",
      "Epoch: 13840/20000, Loss: 0.0000011992377722\n",
      "Epoch: 13850/20000, Loss: 0.0000009815041722\n",
      "Epoch: 13860/20000, Loss: 0.0000007324074431\n",
      "Epoch: 13870/20000, Loss: 0.0000006200523330\n",
      "Epoch: 13880/20000, Loss: 0.0000005896521884\n",
      "Epoch: 13890/20000, Loss: 0.0000005707212267\n",
      "Epoch: 13900/20000, Loss: 0.0000005558798648\n",
      "Epoch: 13910/20000, Loss: 0.0000005521747539\n",
      "Epoch: 13920/20000, Loss: 0.0000005497856250\n",
      "Epoch: 13930/20000, Loss: 0.0000005467604183\n",
      "Epoch: 13940/20000, Loss: 0.0000005443947657\n",
      "Epoch: 13950/20000, Loss: 0.0000005419674380\n",
      "Epoch: 13960/20000, Loss: 0.0000005395896210\n",
      "Epoch: 13970/20000, Loss: 0.0000005372769465\n",
      "Epoch: 13980/20000, Loss: 0.0000005349806429\n",
      "Epoch: 13990/20000, Loss: 0.0000005326964470\n",
      "Epoch: 14000/20000, Loss: 0.0000005304275987\n",
      "Epoch: 14010/20000, Loss: 0.0000005281752919\n",
      "Epoch: 14020/20000, Loss: 0.0000005259310569\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14030/20000, Loss: 0.0000005236981906\n",
      "Epoch: 14040/20000, Loss: 0.0000005214757266\n",
      "Epoch: 14050/20000, Loss: 0.0000005192665640\n",
      "Epoch: 14060/20000, Loss: 0.0000005171888233\n",
      "Epoch: 14070/20000, Loss: 0.0000005284485383\n",
      "Epoch: 14080/20000, Loss: 0.0000032450504932\n",
      "Epoch: 14090/20000, Loss: 0.0000045044321269\n",
      "Epoch: 14100/20000, Loss: 0.0000012985217381\n",
      "Epoch: 14110/20000, Loss: 0.0000007334536463\n",
      "Epoch: 14120/20000, Loss: 0.0000005607990943\n",
      "Epoch: 14130/20000, Loss: 0.0000005261146612\n",
      "Epoch: 14140/20000, Loss: 0.0000005147980460\n",
      "Epoch: 14150/20000, Loss: 0.0000005105007403\n",
      "Epoch: 14160/20000, Loss: 0.0000005055844099\n",
      "Epoch: 14170/20000, Loss: 0.0000004997537530\n",
      "Epoch: 14180/20000, Loss: 0.0000004969562610\n",
      "Epoch: 14190/20000, Loss: 0.0000004946768399\n",
      "Epoch: 14200/20000, Loss: 0.0000004925038866\n",
      "Epoch: 14210/20000, Loss: 0.0000004904553066\n",
      "Epoch: 14220/20000, Loss: 0.0000004884659575\n",
      "Epoch: 14230/20000, Loss: 0.0000004864805305\n",
      "Epoch: 14240/20000, Loss: 0.0000004845204558\n",
      "Epoch: 14250/20000, Loss: 0.0000004825777751\n",
      "Epoch: 14260/20000, Loss: 0.0000004806516927\n",
      "Epoch: 14270/20000, Loss: 0.0000004787411854\n",
      "Epoch: 14280/20000, Loss: 0.0000004768413078\n",
      "Epoch: 14290/20000, Loss: 0.0000004749549305\n",
      "Epoch: 14300/20000, Loss: 0.0000004730794956\n",
      "Epoch: 14310/20000, Loss: 0.0000004712153725\n",
      "Epoch: 14320/20000, Loss: 0.0000004693867197\n",
      "Epoch: 14330/20000, Loss: 0.0000004696275653\n",
      "Epoch: 14340/20000, Loss: 0.0000008732605465\n",
      "Epoch: 14350/20000, Loss: 0.0000069128486757\n",
      "Epoch: 14360/20000, Loss: 0.0000032172586089\n",
      "Epoch: 14370/20000, Loss: 0.0000013096203020\n",
      "Epoch: 14380/20000, Loss: 0.0000007939478905\n",
      "Epoch: 14390/20000, Loss: 0.0000005901931104\n",
      "Epoch: 14400/20000, Loss: 0.0000005035024060\n",
      "Epoch: 14410/20000, Loss: 0.0000004732800960\n",
      "Epoch: 14420/20000, Loss: 0.0000004609793507\n",
      "Epoch: 14430/20000, Loss: 0.0000004556911506\n",
      "Epoch: 14440/20000, Loss: 0.0000004538515839\n",
      "Epoch: 14450/20000, Loss: 0.0000004520050538\n",
      "Epoch: 14460/20000, Loss: 0.0000004500689101\n",
      "Epoch: 14470/20000, Loss: 0.0000004483741520\n",
      "Epoch: 14480/20000, Loss: 0.0000004466674000\n",
      "Epoch: 14490/20000, Loss: 0.0000004450058668\n",
      "Epoch: 14500/20000, Loss: 0.0000004433721301\n",
      "Epoch: 14510/20000, Loss: 0.0000004417589423\n",
      "Epoch: 14520/20000, Loss: 0.0000004401562137\n",
      "Epoch: 14530/20000, Loss: 0.0000004385697707\n",
      "Epoch: 14540/20000, Loss: 0.0000004369971407\n",
      "Epoch: 14550/20000, Loss: 0.0000004354376415\n",
      "Epoch: 14560/20000, Loss: 0.0000004338862141\n",
      "Epoch: 14570/20000, Loss: 0.0000004323506744\n",
      "Epoch: 14580/20000, Loss: 0.0000004308200516\n",
      "Epoch: 14590/20000, Loss: 0.0000004293036397\n",
      "Epoch: 14600/20000, Loss: 0.0000004279696100\n",
      "Epoch: 14610/20000, Loss: 0.0000004535495748\n",
      "Epoch: 14620/20000, Loss: 0.0000068191202445\n",
      "Epoch: 14630/20000, Loss: 0.0000052052973842\n",
      "Epoch: 14640/20000, Loss: 0.0000017958072931\n",
      "Epoch: 14650/20000, Loss: 0.0000008302298511\n",
      "Epoch: 14660/20000, Loss: 0.0000005657985298\n",
      "Epoch: 14670/20000, Loss: 0.0000004607548476\n",
      "Epoch: 14680/20000, Loss: 0.0000004309842154\n",
      "Epoch: 14690/20000, Loss: 0.0000004246236358\n",
      "Epoch: 14700/20000, Loss: 0.0000004214217597\n",
      "Epoch: 14710/20000, Loss: 0.0000004182419957\n",
      "Epoch: 14720/20000, Loss: 0.0000004159637399\n",
      "Epoch: 14730/20000, Loss: 0.0000004145375101\n",
      "Epoch: 14740/20000, Loss: 0.0000004130500884\n",
      "Epoch: 14750/20000, Loss: 0.0000004116242565\n",
      "Epoch: 14760/20000, Loss: 0.0000004102372770\n",
      "Epoch: 14770/20000, Loss: 0.0000004088851995\n",
      "Epoch: 14780/20000, Loss: 0.0000004075477591\n",
      "Epoch: 14790/20000, Loss: 0.0000004062295602\n",
      "Epoch: 14800/20000, Loss: 0.0000004049273059\n",
      "Epoch: 14810/20000, Loss: 0.0000004036313896\n",
      "Epoch: 14820/20000, Loss: 0.0000004023528959\n",
      "Epoch: 14830/20000, Loss: 0.0000004010827013\n",
      "Epoch: 14840/20000, Loss: 0.0000003998225395\n",
      "Epoch: 14850/20000, Loss: 0.0000003985699664\n",
      "Epoch: 14860/20000, Loss: 0.0000003973325420\n",
      "Epoch: 14870/20000, Loss: 0.0000003961534674\n",
      "Epoch: 14880/20000, Loss: 0.0000003977429799\n",
      "Epoch: 14890/20000, Loss: 0.0000007065006002\n",
      "Epoch: 14900/20000, Loss: 0.0000097880183603\n",
      "Epoch: 14910/20000, Loss: 0.0000016386454718\n",
      "Epoch: 14920/20000, Loss: 0.0000006117614362\n",
      "Epoch: 14930/20000, Loss: 0.0000004980331028\n",
      "Epoch: 14940/20000, Loss: 0.0000004704300807\n",
      "Epoch: 14950/20000, Loss: 0.0000004353193788\n",
      "Epoch: 14960/20000, Loss: 0.0000003979919256\n",
      "Epoch: 14970/20000, Loss: 0.0000003894440113\n",
      "Epoch: 14980/20000, Loss: 0.0000003894743088\n",
      "Epoch: 14990/20000, Loss: 0.0000003864278710\n",
      "Epoch: 15000/20000, Loss: 0.0000003850683470\n",
      "Epoch: 15010/20000, Loss: 0.0000003838370048\n",
      "Epoch: 15020/20000, Loss: 0.0000003825805948\n",
      "Epoch: 15030/20000, Loss: 0.0000003814442096\n",
      "Epoch: 15040/20000, Loss: 0.0000003803222910\n",
      "Epoch: 15050/20000, Loss: 0.0000003792215750\n",
      "Epoch: 15060/20000, Loss: 0.0000003781366615\n",
      "Epoch: 15070/20000, Loss: 0.0000003770583703\n",
      "Epoch: 15080/20000, Loss: 0.0000003759905098\n",
      "Epoch: 15090/20000, Loss: 0.0000003749350412\n",
      "Epoch: 15100/20000, Loss: 0.0000003738868486\n",
      "Epoch: 15110/20000, Loss: 0.0000003728721936\n",
      "Epoch: 15120/20000, Loss: 0.0000003736404892\n",
      "Epoch: 15130/20000, Loss: 0.0000006255237395\n",
      "Epoch: 15140/20000, Loss: 0.0000113481155495\n",
      "Epoch: 15150/20000, Loss: 0.0000023350987703\n",
      "Epoch: 15160/20000, Loss: 0.0000010173706642\n",
      "Epoch: 15170/20000, Loss: 0.0000006382716720\n",
      "Epoch: 15180/20000, Loss: 0.0000004766620236\n",
      "Epoch: 15190/20000, Loss: 0.0000004106925360\n",
      "Epoch: 15200/20000, Loss: 0.0000003824782198\n",
      "Epoch: 15210/20000, Loss: 0.0000003701479159\n",
      "Epoch: 15220/20000, Loss: 0.0000003668028512\n",
      "Epoch: 15230/20000, Loss: 0.0000003661554047\n",
      "Epoch: 15240/20000, Loss: 0.0000003645245670\n",
      "Epoch: 15250/20000, Loss: 0.0000003633093684\n",
      "Epoch: 15260/20000, Loss: 0.0000003623168823\n",
      "Epoch: 15270/20000, Loss: 0.0000003613098443\n",
      "Epoch: 15280/20000, Loss: 0.0000003603522885\n",
      "Epoch: 15290/20000, Loss: 0.0000003594125531\n",
      "Epoch: 15300/20000, Loss: 0.0000003584847832\n",
      "Epoch: 15310/20000, Loss: 0.0000003575702294\n",
      "Epoch: 15320/20000, Loss: 0.0000003566651401\n",
      "Epoch: 15330/20000, Loss: 0.0000003557694015\n",
      "Epoch: 15340/20000, Loss: 0.0000003548809957\n",
      "Epoch: 15350/20000, Loss: 0.0000003540017133\n",
      "Epoch: 15360/20000, Loss: 0.0000003531291952\n",
      "Epoch: 15370/20000, Loss: 0.0000003523639123\n",
      "Epoch: 15380/20000, Loss: 0.0000003577487178\n",
      "Epoch: 15390/20000, Loss: 0.0000011655333765\n",
      "Epoch: 15400/20000, Loss: 0.0000019758476810\n",
      "Epoch: 15410/20000, Loss: 0.0000026360742140\n",
      "Epoch: 15420/20000, Loss: 0.0000011984524235\n",
      "Epoch: 15430/20000, Loss: 0.0000006298609492\n",
      "Epoch: 15440/20000, Loss: 0.0000004193925065\n",
      "Epoch: 15450/20000, Loss: 0.0000003575453604\n",
      "Epoch: 15460/20000, Loss: 0.0000003533903055\n",
      "Epoch: 15470/20000, Loss: 0.0000003527855483\n",
      "Epoch: 15480/20000, Loss: 0.0000003478882604\n",
      "Epoch: 15490/20000, Loss: 0.0000003465845566\n",
      "Epoch: 15500/20000, Loss: 0.0000003454309194\n",
      "Epoch: 15510/20000, Loss: 0.0000003444552021\n",
      "Epoch: 15520/20000, Loss: 0.0000003435782219\n",
      "Epoch: 15530/20000, Loss: 0.0000003427503543\n",
      "Epoch: 15540/20000, Loss: 0.0000003419362429\n",
      "Epoch: 15550/20000, Loss: 0.0000003411383602\n",
      "Epoch: 15560/20000, Loss: 0.0000003403516473\n",
      "Epoch: 15570/20000, Loss: 0.0000003395753083\n",
      "Epoch: 15580/20000, Loss: 0.0000003388109917\n",
      "Epoch: 15590/20000, Loss: 0.0000003380514499\n",
      "Epoch: 15600/20000, Loss: 0.0000003372990705\n",
      "Epoch: 15610/20000, Loss: 0.0000003365579460\n",
      "Epoch: 15620/20000, Loss: 0.0000003360538301\n",
      "Epoch: 15630/20000, Loss: 0.0000003602282561\n",
      "Epoch: 15640/20000, Loss: 0.0000046862869567\n",
      "Epoch: 15650/20000, Loss: 0.0000050217972785\n",
      "Epoch: 15660/20000, Loss: 0.0000019575782062\n",
      "Epoch: 15670/20000, Loss: 0.0000007992003930\n",
      "Epoch: 15680/20000, Loss: 0.0000004222976315\n",
      "Epoch: 15690/20000, Loss: 0.0000003460455389\n",
      "Epoch: 15700/20000, Loss: 0.0000003353514728\n",
      "Epoch: 15710/20000, Loss: 0.0000003334504584\n",
      "Epoch: 15720/20000, Loss: 0.0000003325257580\n",
      "Epoch: 15730/20000, Loss: 0.0000003317621520\n",
      "Epoch: 15740/20000, Loss: 0.0000003308602174\n",
      "Epoch: 15750/20000, Loss: 0.0000003298845854\n",
      "Epoch: 15760/20000, Loss: 0.0000003290424218\n",
      "Epoch: 15770/20000, Loss: 0.0000003283488184\n",
      "Epoch: 15780/20000, Loss: 0.0000003276688858\n",
      "Epoch: 15790/20000, Loss: 0.0000003269930744\n",
      "Epoch: 15800/20000, Loss: 0.0000003263322981\n",
      "Epoch: 15810/20000, Loss: 0.0000003256816399\n",
      "Epoch: 15820/20000, Loss: 0.0000003250334544\n",
      "Epoch: 15830/20000, Loss: 0.0000003244285836\n",
      "Epoch: 15840/20000, Loss: 0.0000003260389860\n",
      "Epoch: 15850/20000, Loss: 0.0000006275046189\n",
      "Epoch: 15860/20000, Loss: 0.0000088118158601\n",
      "Epoch: 15870/20000, Loss: 0.0000014928197061\n",
      "Epoch: 15880/20000, Loss: 0.0000004318445690\n",
      "Epoch: 15890/20000, Loss: 0.0000003959057722\n",
      "Epoch: 15900/20000, Loss: 0.0000004020253925\n",
      "Epoch: 15910/20000, Loss: 0.0000003667414887\n",
      "Epoch: 15920/20000, Loss: 0.0000003285016703\n",
      "Epoch: 15930/20000, Loss: 0.0000003240233752\n",
      "Epoch: 15940/20000, Loss: 0.0000003227348486\n",
      "Epoch: 15950/20000, Loss: 0.0000003204993106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15960/20000, Loss: 0.0000003196527700\n",
      "Epoch: 15970/20000, Loss: 0.0000003189289259\n",
      "Epoch: 15980/20000, Loss: 0.0000003182045702\n",
      "Epoch: 15990/20000, Loss: 0.0000003175628080\n",
      "Epoch: 16000/20000, Loss: 0.0000003169477054\n",
      "Epoch: 16010/20000, Loss: 0.0000003163478652\n",
      "Epoch: 16020/20000, Loss: 0.0000003157540789\n",
      "Epoch: 16030/20000, Loss: 0.0000003151677674\n",
      "Epoch: 16040/20000, Loss: 0.0000003145879646\n",
      "Epoch: 16050/20000, Loss: 0.0000003140125671\n",
      "Epoch: 16060/20000, Loss: 0.0000003134441897\n",
      "Epoch: 16070/20000, Loss: 0.0000003128894832\n",
      "Epoch: 16080/20000, Loss: 0.0000003129722757\n",
      "Epoch: 16090/20000, Loss: 0.0000003903466848\n",
      "Epoch: 16100/20000, Loss: 0.0000108908607217\n",
      "Epoch: 16110/20000, Loss: 0.0000011481171214\n",
      "Epoch: 16120/20000, Loss: 0.0000008200233310\n",
      "Epoch: 16130/20000, Loss: 0.0000004785063084\n",
      "Epoch: 16140/20000, Loss: 0.0000003801980313\n",
      "Epoch: 16150/20000, Loss: 0.0000003500188370\n",
      "Epoch: 16160/20000, Loss: 0.0000003337695489\n",
      "Epoch: 16170/20000, Loss: 0.0000003201786001\n",
      "Epoch: 16180/20000, Loss: 0.0000003118879306\n",
      "Epoch: 16190/20000, Loss: 0.0000003103605479\n",
      "Epoch: 16200/20000, Loss: 0.0000003098569152\n",
      "Epoch: 16210/20000, Loss: 0.0000003087777714\n",
      "Epoch: 16220/20000, Loss: 0.0000003082145099\n",
      "Epoch: 16230/20000, Loss: 0.0000003075706161\n",
      "Epoch: 16240/20000, Loss: 0.0000003069974639\n",
      "Epoch: 16250/20000, Loss: 0.0000003064401142\n",
      "Epoch: 16260/20000, Loss: 0.0000003058924563\n",
      "Epoch: 16270/20000, Loss: 0.0000003053535238\n",
      "Epoch: 16280/20000, Loss: 0.0000003048225210\n",
      "Epoch: 16290/20000, Loss: 0.0000003042972594\n",
      "Epoch: 16300/20000, Loss: 0.0000003037771421\n",
      "Epoch: 16310/20000, Loss: 0.0000003032624249\n",
      "Epoch: 16320/20000, Loss: 0.0000003027512037\n",
      "Epoch: 16330/20000, Loss: 0.0000003022437909\n",
      "Epoch: 16340/20000, Loss: 0.0000003017455583\n",
      "Epoch: 16350/20000, Loss: 0.0000003015646826\n",
      "Epoch: 16360/20000, Loss: 0.0000003421869508\n",
      "Epoch: 16370/20000, Loss: 0.0000077553931987\n",
      "Epoch: 16380/20000, Loss: 0.0000038458933886\n",
      "Epoch: 16390/20000, Loss: 0.0000014335797687\n",
      "Epoch: 16400/20000, Loss: 0.0000005262915010\n",
      "Epoch: 16410/20000, Loss: 0.0000003355900731\n",
      "Epoch: 16420/20000, Loss: 0.0000003118911991\n",
      "Epoch: 16430/20000, Loss: 0.0000003087047560\n",
      "Epoch: 16440/20000, Loss: 0.0000003053972364\n",
      "Epoch: 16450/20000, Loss: 0.0000003032725715\n",
      "Epoch: 16460/20000, Loss: 0.0000003010300702\n",
      "Epoch: 16470/20000, Loss: 0.0000002991688177\n",
      "Epoch: 16480/20000, Loss: 0.0000002985504750\n",
      "Epoch: 16490/20000, Loss: 0.0000002979561771\n",
      "Epoch: 16500/20000, Loss: 0.0000002973625044\n",
      "Epoch: 16510/20000, Loss: 0.0000002968453998\n",
      "Epoch: 16520/20000, Loss: 0.0000002963320753\n",
      "Epoch: 16530/20000, Loss: 0.0000002958337006\n",
      "Epoch: 16540/20000, Loss: 0.0000002953439378\n",
      "Epoch: 16550/20000, Loss: 0.0000002948622466\n",
      "Epoch: 16560/20000, Loss: 0.0000002943866377\n",
      "Epoch: 16570/20000, Loss: 0.0000002939141837\n",
      "Epoch: 16580/20000, Loss: 0.0000002934464760\n",
      "Epoch: 16590/20000, Loss: 0.0000002929829179\n",
      "Epoch: 16600/20000, Loss: 0.0000002925235663\n",
      "Epoch: 16610/20000, Loss: 0.0000002921582052\n",
      "Epoch: 16620/20000, Loss: 0.0000003000262723\n",
      "Epoch: 16630/20000, Loss: 0.0000014614768133\n",
      "Epoch: 16640/20000, Loss: 0.0000064879423007\n",
      "Epoch: 16650/20000, Loss: 0.0000013539735164\n",
      "Epoch: 16660/20000, Loss: 0.0000007069942285\n",
      "Epoch: 16670/20000, Loss: 0.0000004665656377\n",
      "Epoch: 16680/20000, Loss: 0.0000003007093881\n",
      "Epoch: 16690/20000, Loss: 0.0000003050762132\n",
      "Epoch: 16700/20000, Loss: 0.0000002983401544\n",
      "Epoch: 16710/20000, Loss: 0.0000002927199318\n",
      "Epoch: 16720/20000, Loss: 0.0000002904219798\n",
      "Epoch: 16730/20000, Loss: 0.0000002891189581\n",
      "Epoch: 16740/20000, Loss: 0.0000002881764942\n",
      "Epoch: 16750/20000, Loss: 0.0000002877564498\n",
      "Epoch: 16760/20000, Loss: 0.0000002872133393\n",
      "Epoch: 16770/20000, Loss: 0.0000002867834610\n",
      "Epoch: 16780/20000, Loss: 0.0000002863824875\n",
      "Epoch: 16790/20000, Loss: 0.0000002870053493\n",
      "Epoch: 16800/20000, Loss: 0.0000003811285580\n",
      "Epoch: 16810/20000, Loss: 0.0000090909870778\n",
      "Epoch: 16820/20000, Loss: 0.0000017152541432\n",
      "Epoch: 16830/20000, Loss: 0.0000013648475488\n",
      "Epoch: 16840/20000, Loss: 0.0000006750923376\n",
      "Epoch: 16850/20000, Loss: 0.0000003684706655\n",
      "Epoch: 16860/20000, Loss: 0.0000002955186460\n",
      "Epoch: 16870/20000, Loss: 0.0000003008583462\n",
      "Epoch: 16880/20000, Loss: 0.0000002904098437\n",
      "Epoch: 16890/20000, Loss: 0.0000002854676779\n",
      "Epoch: 16900/20000, Loss: 0.0000002848750569\n",
      "Epoch: 16910/20000, Loss: 0.0000002839666706\n",
      "Epoch: 16920/20000, Loss: 0.0000002832766199\n",
      "Epoch: 16930/20000, Loss: 0.0000002828092249\n",
      "Epoch: 16940/20000, Loss: 0.0000002823557566\n",
      "Epoch: 16950/20000, Loss: 0.0000002819142537\n",
      "Epoch: 16960/20000, Loss: 0.0000002814850575\n",
      "Epoch: 16970/20000, Loss: 0.0000002810645015\n",
      "Epoch: 16980/20000, Loss: 0.0000002806538362\n",
      "Epoch: 16990/20000, Loss: 0.0000002802449330\n",
      "Epoch: 17000/20000, Loss: 0.0000002798413732\n",
      "Epoch: 17010/20000, Loss: 0.0000002794410818\n",
      "Epoch: 17020/20000, Loss: 0.0000002790439453\n",
      "Epoch: 17030/20000, Loss: 0.0000002786505604\n",
      "Epoch: 17040/20000, Loss: 0.0000002786779305\n",
      "Epoch: 17050/20000, Loss: 0.0000003854168824\n",
      "Epoch: 17060/20000, Loss: 0.0000167911312019\n",
      "Epoch: 17070/20000, Loss: 0.0000031533274978\n",
      "Epoch: 17080/20000, Loss: 0.0000015788881456\n",
      "Epoch: 17090/20000, Loss: 0.0000004811274152\n",
      "Epoch: 17100/20000, Loss: 0.0000003683247485\n",
      "Epoch: 17110/20000, Loss: 0.0000003453747297\n",
      "Epoch: 17120/20000, Loss: 0.0000003033645442\n",
      "Epoch: 17130/20000, Loss: 0.0000002853771832\n",
      "Epoch: 17140/20000, Loss: 0.0000002803177210\n",
      "Epoch: 17150/20000, Loss: 0.0000002786823643\n",
      "Epoch: 17160/20000, Loss: 0.0000002778192822\n",
      "Epoch: 17170/20000, Loss: 0.0000002771757011\n",
      "Epoch: 17180/20000, Loss: 0.0000002766193461\n",
      "Epoch: 17190/20000, Loss: 0.0000002761152587\n",
      "Epoch: 17200/20000, Loss: 0.0000002756556228\n",
      "Epoch: 17210/20000, Loss: 0.0000002752264550\n",
      "Epoch: 17220/20000, Loss: 0.0000002748088264\n",
      "Epoch: 17230/20000, Loss: 0.0000002743988432\n",
      "Epoch: 17240/20000, Loss: 0.0000002739978413\n",
      "Epoch: 17250/20000, Loss: 0.0000002736022680\n",
      "Epoch: 17260/20000, Loss: 0.0000002732156190\n",
      "Epoch: 17270/20000, Loss: 0.0000002728282027\n",
      "Epoch: 17280/20000, Loss: 0.0000002724466697\n",
      "Epoch: 17290/20000, Loss: 0.0000002720661598\n",
      "Epoch: 17300/20000, Loss: 0.0000002716899701\n",
      "Epoch: 17310/20000, Loss: 0.0000002713159120\n",
      "Epoch: 17320/20000, Loss: 0.0000002709446676\n",
      "Epoch: 17330/20000, Loss: 0.0000002705763222\n",
      "Epoch: 17340/20000, Loss: 0.0000002702134339\n",
      "Epoch: 17350/20000, Loss: 0.0000002700635946\n",
      "Epoch: 17360/20000, Loss: 0.0000002899884066\n",
      "Epoch: 17370/20000, Loss: 0.0000035929431306\n",
      "Epoch: 17380/20000, Loss: 0.0000039045999074\n",
      "Epoch: 17390/20000, Loss: 0.0000007344636401\n",
      "Epoch: 17400/20000, Loss: 0.0000003785985143\n",
      "Epoch: 17410/20000, Loss: 0.0000003036963676\n",
      "Epoch: 17420/20000, Loss: 0.0000002944715334\n",
      "Epoch: 17430/20000, Loss: 0.0000002925043532\n",
      "Epoch: 17440/20000, Loss: 0.0000002808167778\n",
      "Epoch: 17450/20000, Loss: 0.0000002703785924\n",
      "Epoch: 17460/20000, Loss: 0.0000002694648913\n",
      "Epoch: 17470/20000, Loss: 0.0000002687870335\n",
      "Epoch: 17480/20000, Loss: 0.0000002679981606\n",
      "Epoch: 17490/20000, Loss: 0.0000002675169810\n",
      "Epoch: 17500/20000, Loss: 0.0000002671060884\n",
      "Epoch: 17510/20000, Loss: 0.0000002666895966\n",
      "Epoch: 17520/20000, Loss: 0.0000002662987981\n",
      "Epoch: 17530/20000, Loss: 0.0000002659202210\n",
      "Epoch: 17540/20000, Loss: 0.0000002655482376\n",
      "Epoch: 17550/20000, Loss: 0.0000002651842976\n",
      "Epoch: 17560/20000, Loss: 0.0000002648211535\n",
      "Epoch: 17570/20000, Loss: 0.0000002644594304\n",
      "Epoch: 17580/20000, Loss: 0.0000002641036190\n",
      "Epoch: 17590/20000, Loss: 0.0000002637515877\n",
      "Epoch: 17600/20000, Loss: 0.0000002634073724\n",
      "Epoch: 17610/20000, Loss: 0.0000002634793361\n",
      "Epoch: 17620/20000, Loss: 0.0000003115353593\n",
      "Epoch: 17630/20000, Loss: 0.0000076346241258\n",
      "Epoch: 17640/20000, Loss: 0.0000028125762128\n",
      "Epoch: 17650/20000, Loss: 0.0000010253029359\n",
      "Epoch: 17660/20000, Loss: 0.0000004459034244\n",
      "Epoch: 17670/20000, Loss: 0.0000003142950220\n",
      "Epoch: 17680/20000, Loss: 0.0000002827962362\n",
      "Epoch: 17690/20000, Loss: 0.0000002726440869\n",
      "Epoch: 17700/20000, Loss: 0.0000002696080799\n",
      "Epoch: 17710/20000, Loss: 0.0000002660135010\n",
      "Epoch: 17720/20000, Loss: 0.0000002630384586\n",
      "Epoch: 17730/20000, Loss: 0.0000002618447468\n",
      "Epoch: 17740/20000, Loss: 0.0000002615108485\n",
      "Epoch: 17750/20000, Loss: 0.0000002609938861\n",
      "Epoch: 17760/20000, Loss: 0.0000002605884504\n",
      "Epoch: 17770/20000, Loss: 0.0000002602002667\n",
      "Epoch: 17780/20000, Loss: 0.0000002598333140\n",
      "Epoch: 17790/20000, Loss: 0.0000002594686919\n",
      "Epoch: 17800/20000, Loss: 0.0000002591133921\n",
      "Epoch: 17810/20000, Loss: 0.0000002587627534\n",
      "Epoch: 17820/20000, Loss: 0.0000002584179981\n",
      "Epoch: 17830/20000, Loss: 0.0000002580727312\n",
      "Epoch: 17840/20000, Loss: 0.0000002577339728\n",
      "Epoch: 17850/20000, Loss: 0.0000002573947029\n",
      "Epoch: 17860/20000, Loss: 0.0000002570668300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17870/20000, Loss: 0.0000002578678107\n",
      "Epoch: 17880/20000, Loss: 0.0000005203983164\n",
      "Epoch: 17890/20000, Loss: 0.0000090546382125\n",
      "Epoch: 17900/20000, Loss: 0.0000007310044339\n",
      "Epoch: 17910/20000, Loss: 0.0000005418845603\n",
      "Epoch: 17920/20000, Loss: 0.0000004709115444\n",
      "Epoch: 17930/20000, Loss: 0.0000003452717294\n",
      "Epoch: 17940/20000, Loss: 0.0000002841460969\n",
      "Epoch: 17950/20000, Loss: 0.0000002598477238\n",
      "Epoch: 17960/20000, Loss: 0.0000002579581917\n",
      "Epoch: 17970/20000, Loss: 0.0000002574032578\n",
      "Epoch: 17980/20000, Loss: 0.0000002558047925\n",
      "Epoch: 17990/20000, Loss: 0.0000002553722140\n",
      "Epoch: 18000/20000, Loss: 0.0000002549034832\n",
      "Epoch: 18010/20000, Loss: 0.0000002544891800\n",
      "Epoch: 18020/20000, Loss: 0.0000002541283664\n",
      "Epoch: 18030/20000, Loss: 0.0000002537759087\n",
      "Epoch: 18040/20000, Loss: 0.0000002534326882\n",
      "Epoch: 18050/20000, Loss: 0.0000002530966867\n",
      "Epoch: 18060/20000, Loss: 0.0000002527663412\n",
      "Epoch: 18070/20000, Loss: 0.0000002524384399\n",
      "Epoch: 18080/20000, Loss: 0.0000002521144324\n",
      "Epoch: 18090/20000, Loss: 0.0000002517913060\n",
      "Epoch: 18100/20000, Loss: 0.0000002514855169\n",
      "Epoch: 18110/20000, Loss: 0.0000002516725601\n",
      "Epoch: 18120/20000, Loss: 0.0000002958018968\n",
      "Epoch: 18130/20000, Loss: 0.0000060619227042\n",
      "Epoch: 18140/20000, Loss: 0.0000044233324843\n",
      "Epoch: 18150/20000, Loss: 0.0000015509215245\n",
      "Epoch: 18160/20000, Loss: 0.0000006006644071\n",
      "Epoch: 18170/20000, Loss: 0.0000003223831300\n",
      "Epoch: 18180/20000, Loss: 0.0000002581325589\n",
      "Epoch: 18190/20000, Loss: 0.0000002592925057\n",
      "Epoch: 18200/20000, Loss: 0.0000002601297524\n",
      "Epoch: 18210/20000, Loss: 0.0000002524109846\n",
      "Epoch: 18220/20000, Loss: 0.0000002509332830\n",
      "Epoch: 18230/20000, Loss: 0.0000002503850851\n",
      "Epoch: 18240/20000, Loss: 0.0000002497613991\n",
      "Epoch: 18250/20000, Loss: 0.0000002492911619\n",
      "Epoch: 18260/20000, Loss: 0.0000002489265682\n",
      "Epoch: 18270/20000, Loss: 0.0000002485601556\n",
      "Epoch: 18280/20000, Loss: 0.0000002482074990\n",
      "Epoch: 18290/20000, Loss: 0.0000002478664669\n",
      "Epoch: 18300/20000, Loss: 0.0000002475313750\n",
      "Epoch: 18310/20000, Loss: 0.0000002472017968\n",
      "Epoch: 18320/20000, Loss: 0.0000002468769367\n",
      "Epoch: 18330/20000, Loss: 0.0000002465556292\n",
      "Epoch: 18340/20000, Loss: 0.0000002462364534\n",
      "Epoch: 18350/20000, Loss: 0.0000002459195514\n",
      "Epoch: 18360/20000, Loss: 0.0000002456040420\n",
      "Epoch: 18370/20000, Loss: 0.0000002453029140\n",
      "Epoch: 18380/20000, Loss: 0.0000002466495630\n",
      "Epoch: 18390/20000, Loss: 0.0000007888957043\n",
      "Epoch: 18400/20000, Loss: 0.0000020106920147\n",
      "Epoch: 18410/20000, Loss: 0.0000006951026421\n",
      "Epoch: 18420/20000, Loss: 0.0000009739495681\n",
      "Epoch: 18430/20000, Loss: 0.0000006281579203\n",
      "Epoch: 18440/20000, Loss: 0.0000002694746684\n",
      "Epoch: 18450/20000, Loss: 0.0000002696847616\n",
      "Epoch: 18460/20000, Loss: 0.0000002651478326\n",
      "Epoch: 18470/20000, Loss: 0.0000002532619590\n",
      "Epoch: 18480/20000, Loss: 0.0000002481413901\n",
      "Epoch: 18490/20000, Loss: 0.0000002462114139\n",
      "Epoch: 18500/20000, Loss: 0.0000002453909644\n",
      "Epoch: 18510/20000, Loss: 0.0000002448163912\n",
      "Epoch: 18520/20000, Loss: 0.0000002443353253\n",
      "Epoch: 18530/20000, Loss: 0.0000002438970057\n",
      "Epoch: 18540/20000, Loss: 0.0000002434968565\n",
      "Epoch: 18550/20000, Loss: 0.0000002431246457\n",
      "Epoch: 18560/20000, Loss: 0.0000002427669870\n",
      "Epoch: 18570/20000, Loss: 0.0000002424188494\n",
      "Epoch: 18580/20000, Loss: 0.0000002420775900\n",
      "Epoch: 18590/20000, Loss: 0.0000002417443454\n",
      "Epoch: 18600/20000, Loss: 0.0000002414151652\n",
      "Epoch: 18610/20000, Loss: 0.0000002410927209\n",
      "Epoch: 18620/20000, Loss: 0.0000002407710156\n",
      "Epoch: 18630/20000, Loss: 0.0000002404549377\n",
      "Epoch: 18640/20000, Loss: 0.0000002401419295\n",
      "Epoch: 18650/20000, Loss: 0.0000002399273740\n",
      "Epoch: 18660/20000, Loss: 0.0000002455894617\n",
      "Epoch: 18670/20000, Loss: 0.0000008949933772\n",
      "Epoch: 18680/20000, Loss: 0.0000013173196294\n",
      "Epoch: 18690/20000, Loss: 0.0000002785489812\n",
      "Epoch: 18700/20000, Loss: 0.0000004106805704\n",
      "Epoch: 18710/20000, Loss: 0.0000002682148477\n",
      "Epoch: 18720/20000, Loss: 0.0000002664878593\n",
      "Epoch: 18730/20000, Loss: 0.0000004360075252\n",
      "Epoch: 18740/20000, Loss: 0.0000021901189484\n",
      "Epoch: 18750/20000, Loss: 0.0000002962980830\n",
      "Epoch: 18760/20000, Loss: 0.0000002415264362\n",
      "Epoch: 18770/20000, Loss: 0.0000002414191442\n",
      "Epoch: 18780/20000, Loss: 0.0000002607380338\n",
      "Epoch: 18790/20000, Loss: 0.0000002627125184\n",
      "Epoch: 18800/20000, Loss: 0.0000002367382734\n",
      "Epoch: 18810/20000, Loss: 0.0000002439461753\n",
      "Epoch: 18820/20000, Loss: 0.0000002608129535\n",
      "Epoch: 18830/20000, Loss: 0.0000005185435725\n",
      "Epoch: 18840/20000, Loss: 0.0000035239872886\n",
      "Epoch: 18850/20000, Loss: 0.0000012054416629\n",
      "Epoch: 18860/20000, Loss: 0.0000006470223752\n",
      "Epoch: 18870/20000, Loss: 0.0000003903000447\n",
      "Epoch: 18880/20000, Loss: 0.0000002938362229\n",
      "Epoch: 18890/20000, Loss: 0.0000002591205543\n",
      "Epoch: 18900/20000, Loss: 0.0000002400381334\n",
      "Epoch: 18910/20000, Loss: 0.0000002353117026\n",
      "Epoch: 18920/20000, Loss: 0.0000002359481215\n",
      "Epoch: 18930/20000, Loss: 0.0000002377667130\n",
      "Epoch: 18940/20000, Loss: 0.0000002583291518\n",
      "Epoch: 18950/20000, Loss: 0.0000007903649930\n",
      "Epoch: 18960/20000, Loss: 0.0000037655420329\n",
      "Epoch: 18970/20000, Loss: 0.0000007261907058\n",
      "Epoch: 18980/20000, Loss: 0.0000002827103742\n",
      "Epoch: 18990/20000, Loss: 0.0000003546765583\n",
      "Epoch: 19000/20000, Loss: 0.0000002810072317\n",
      "Epoch: 19010/20000, Loss: 0.0000002452001695\n",
      "Epoch: 19020/20000, Loss: 0.0000002366089404\n",
      "Epoch: 19030/20000, Loss: 0.0000002345329904\n",
      "Epoch: 19040/20000, Loss: 0.0000002333706703\n",
      "Epoch: 19050/20000, Loss: 0.0000002317663501\n",
      "Epoch: 19060/20000, Loss: 0.0000002317494960\n",
      "Epoch: 19070/20000, Loss: 0.0000002314011738\n",
      "Epoch: 19080/20000, Loss: 0.0000002328999926\n",
      "Epoch: 19090/20000, Loss: 0.0000002810829756\n",
      "Epoch: 19100/20000, Loss: 0.0000021914520403\n",
      "Epoch: 19110/20000, Loss: 0.0000022647168407\n",
      "Epoch: 19120/20000, Loss: 0.0000004079383871\n",
      "Epoch: 19130/20000, Loss: 0.0000002413555933\n",
      "Epoch: 19140/20000, Loss: 0.0000002315073857\n",
      "Epoch: 19150/20000, Loss: 0.0000002367624461\n",
      "Epoch: 19160/20000, Loss: 0.0000002409134368\n",
      "Epoch: 19170/20000, Loss: 0.0000002360205684\n",
      "Epoch: 19180/20000, Loss: 0.0000002294895580\n",
      "Epoch: 19190/20000, Loss: 0.0000002289886680\n",
      "Epoch: 19200/20000, Loss: 0.0000002309132014\n",
      "Epoch: 19210/20000, Loss: 0.0000002751188788\n",
      "Epoch: 19220/20000, Loss: 0.0000021632649805\n",
      "Epoch: 19230/20000, Loss: 0.0000003715678076\n",
      "Epoch: 19240/20000, Loss: 0.0000011196761989\n",
      "Epoch: 19250/20000, Loss: 0.0000002839599915\n",
      "Epoch: 19260/20000, Loss: 0.0000003000127435\n",
      "Epoch: 19270/20000, Loss: 0.0000002700536470\n",
      "Epoch: 19280/20000, Loss: 0.0000002323383228\n",
      "Epoch: 19290/20000, Loss: 0.0000002277359528\n",
      "Epoch: 19300/20000, Loss: 0.0000002272073374\n",
      "Epoch: 19310/20000, Loss: 0.0000002268060371\n",
      "Epoch: 19320/20000, Loss: 0.0000002266285577\n",
      "Epoch: 19330/20000, Loss: 0.0000002262509611\n",
      "Epoch: 19340/20000, Loss: 0.0000002257765601\n",
      "Epoch: 19350/20000, Loss: 0.0000002254489715\n",
      "Epoch: 19360/20000, Loss: 0.0000002252089217\n",
      "Epoch: 19370/20000, Loss: 0.0000002263367662\n",
      "Epoch: 19380/20000, Loss: 0.0000003068344370\n",
      "Epoch: 19390/20000, Loss: 0.0000063970660449\n",
      "Epoch: 19400/20000, Loss: 0.0000030774594961\n",
      "Epoch: 19410/20000, Loss: 0.0000008393210464\n",
      "Epoch: 19420/20000, Loss: 0.0000003085978619\n",
      "Epoch: 19430/20000, Loss: 0.0000002810566855\n",
      "Epoch: 19440/20000, Loss: 0.0000002628396203\n",
      "Epoch: 19450/20000, Loss: 0.0000002335569036\n",
      "Epoch: 19460/20000, Loss: 0.0000002283569955\n",
      "Epoch: 19470/20000, Loss: 0.0000002256033866\n",
      "Epoch: 19480/20000, Loss: 0.0000002249700941\n",
      "Epoch: 19490/20000, Loss: 0.0000002237806171\n",
      "Epoch: 19500/20000, Loss: 0.0000002233725382\n",
      "Epoch: 19510/20000, Loss: 0.0000002230260350\n",
      "Epoch: 19520/20000, Loss: 0.0000002226778548\n",
      "Epoch: 19530/20000, Loss: 0.0000002223509625\n",
      "Epoch: 19540/20000, Loss: 0.0000002220326394\n",
      "Epoch: 19550/20000, Loss: 0.0000002217282713\n",
      "Epoch: 19560/20000, Loss: 0.0000002214282517\n",
      "Epoch: 19570/20000, Loss: 0.0000002211346981\n",
      "Epoch: 19580/20000, Loss: 0.0000002208452941\n",
      "Epoch: 19590/20000, Loss: 0.0000002205840843\n",
      "Epoch: 19600/20000, Loss: 0.0000002214029280\n",
      "Epoch: 19610/20000, Loss: 0.0000003233714096\n",
      "Epoch: 19620/20000, Loss: 0.0000050725452638\n",
      "Epoch: 19630/20000, Loss: 0.0000026089726362\n",
      "Epoch: 19640/20000, Loss: 0.0000009629626447\n",
      "Epoch: 19650/20000, Loss: 0.0000004926672545\n",
      "Epoch: 19660/20000, Loss: 0.0000002917854829\n",
      "Epoch: 19670/20000, Loss: 0.0000002661036547\n",
      "Epoch: 19680/20000, Loss: 0.0000002227421874\n",
      "Epoch: 19690/20000, Loss: 0.0000002271805926\n",
      "Epoch: 19700/20000, Loss: 0.0000002222874826\n",
      "Epoch: 19710/20000, Loss: 0.0000002196970996\n",
      "Epoch: 19720/20000, Loss: 0.0000002190559201\n",
      "Epoch: 19730/20000, Loss: 0.0000002187087489\n",
      "Epoch: 19740/20000, Loss: 0.0000002183963375\n",
      "Epoch: 19750/20000, Loss: 0.0000002180812828\n",
      "Epoch: 19760/20000, Loss: 0.0000002177686298\n",
      "Epoch: 19770/20000, Loss: 0.0000002174848674\n",
      "Epoch: 19780/20000, Loss: 0.0000002172094327\n",
      "Epoch: 19790/20000, Loss: 0.0000002170717295\n",
      "Epoch: 19800/20000, Loss: 0.0000002218211534\n",
      "Epoch: 19810/20000, Loss: 0.0000006327026085\n",
      "Epoch: 19820/20000, Loss: 0.0000049436812333\n",
      "Epoch: 19830/20000, Loss: 0.0000010634748833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19840/20000, Loss: 0.0000002607196450\n",
      "Epoch: 19850/20000, Loss: 0.0000003868623537\n",
      "Epoch: 19860/20000, Loss: 0.0000002945962478\n",
      "Epoch: 19870/20000, Loss: 0.0000002201454521\n",
      "Epoch: 19880/20000, Loss: 0.0000002287185481\n",
      "Epoch: 19890/20000, Loss: 0.0000002171015865\n",
      "Epoch: 19900/20000, Loss: 0.0000002179158969\n",
      "Epoch: 19910/20000, Loss: 0.0000002163352946\n",
      "Epoch: 19920/20000, Loss: 0.0000002156631638\n",
      "Epoch: 19930/20000, Loss: 0.0000002153125536\n",
      "Epoch: 19940/20000, Loss: 0.0000002149830607\n",
      "Epoch: 19950/20000, Loss: 0.0000002146635865\n",
      "Epoch: 19960/20000, Loss: 0.0000002143618616\n",
      "Epoch: 19970/20000, Loss: 0.0000002140700275\n",
      "Epoch: 19980/20000, Loss: 0.0000002137820019\n",
      "Epoch: 19990/20000, Loss: 0.0000002134995327\n",
      "Epoch: 20000/20000, Loss: 0.0000002132230890\n"
     ]
    }
   ],
   "source": [
    "# Create LEM instance\n",
    "lem = LEM(input_size, hidden_size, output_size, dt=0.1)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(lem.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    output = lem(input_tensor)\n",
    "    loss = criterion(output, target_tensor)\n",
    "\n",
    "    # Backward and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print progress\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch: {epoch + 1}/{num_epochs}, Loss: {loss.item():.16f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1da66d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 256])\n",
      "torch.Size([1, 20, 256])\n"
     ]
    }
   ],
   "source": [
    "print(test_tensor.shape)\n",
    "prediction_tensor = torch.zeros(1, 20, 256).float()\n",
    "print(prediction_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0543daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    prediction = lem(test_tensor)\n",
    "    prediction = prediction.view(1, 1, 256).float()\n",
    "    prediction_tensor[:, 0, :] = prediction\n",
    "    for i in range(19):\n",
    "        prediction = lem(prediction)\n",
    "        prediction = prediction.view(1, 1, 256).float()\n",
    "        prediction_tensor[:, i+1, :] = prediction\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6b9bad",
   "metadata": {},
   "source": [
    "### Four different types of error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c33b0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exact Solution\n",
    "\n",
    "u_test = u_1.T\n",
    "u_test_full = u_test[80:100, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00c8fa22",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_tensor = torch.squeeze(prediction_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "334bf0be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11699/1744225238.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  u_test_full_tensor = torch.tensor(u_test_full**2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 256])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extrapolation\n",
    "\n",
    "k1 = ( prediction_tensor - u_test_full)**2\n",
    "u_test_full_tensor = torch.tensor(u_test_full**2)\n",
    "u_test_full_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01080c4f",
   "metadata": {},
   "source": [
    "### L^2 norm error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33c17bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relative Error Test:  1.187628627069187 %\n"
     ]
    }
   ],
   "source": [
    "# Compute the relative L2 error norm (generalization error)\n",
    "relative_error_test = torch.mean(k1)/ torch.mean(u_test_full_tensor)\n",
    "\n",
    "print(\"Relative Error Test: \", relative_error_test.item(), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3fa35b",
   "metadata": {},
   "source": [
    "### Max absolute norm error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cf8637",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_abs = torch.max(torch.abs(prediction_tensor - u_test_full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e65482",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(R_abs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678810f2",
   "metadata": {},
   "source": [
    "### Explained variance score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c72385",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "a = prediction_tensor\n",
    "b = u_test_full\n",
    "# Assuming 'a' is your predicted values (model's predictions) and 'b' is the true values (ground truth)\n",
    "# Make sure 'a' and 'b' are PyTorch tensors\n",
    "# a = torch.tensor(a)\n",
    "b = torch.tensor(b)\n",
    "# Calculate the mean of 'b'\n",
    "mean_b = torch.mean(b)\n",
    "\n",
    "# Calculate the Explained Variance Score\n",
    "numerator = torch.var(b - a)  # Variance of the differences between 'b' and 'a'\n",
    "denominator = torch.var(b)    # Variance of 'b'\n",
    "evs = 1 - numerator / denominator\n",
    "\n",
    "print(\"Explained Variance Score:\", evs.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f664baf6",
   "metadata": {},
   "source": [
    "### Mean absolute error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fc2394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the relative L2 error norm (generalization error)\n",
    "relative_error_test = torch.mean(torch.abs(prediction_tensor - u_test_full))\n",
    "\n",
    "print(\"Relative Error Test: \", relative_error_test, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e50e9e",
   "metadata": {},
   "source": [
    "### Contour plot for PINN (80 percent) and (20 percentage lem prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3eec75",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prediction_tensor.shape)\n",
    "prediction_tensor = torch.squeeze(prediction_tensor)\n",
    "input_tensor = torch.squeeze(input_tensor)\n",
    "\n",
    "conc_u = torch.squeeze(input_tensor)\n",
    "concatenated_tensor = torch.cat((conc_u, prediction_tensor), dim=0)\n",
    "\n",
    "x1 = np.linspace(-1, 1, 256)\n",
    "t1 = np.linspace(0, 1, 99)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e393a1e0",
   "metadata": {},
   "source": [
    "### Snapshot time plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f91104",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Create the figure and axis objects with reduced width\n",
    "fig, ax = plt.subplots(figsize=(5, 5))  # You can adjust the width (7 inches) and height (5 inches) as needed\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "final_time_output = prediction_tensor[3, :]\n",
    "final_out = final_time_output.detach().numpy().reshape(-1, 1)\n",
    "final_true = u_1[:, 83].reshape(-1, 1)\n",
    "\n",
    "# Plot the data with red and blue lines, one with dotted and one with solid style\n",
    "ax.plot(x, final_out, color='red', linestyle='dotted', linewidth=12, label='Prediction')\n",
    "ax.plot(x, final_true, color='blue', linestyle='solid', linewidth=7, label='True')\n",
    "\n",
    "\n",
    "# Set the axis labels with bold font weight\n",
    "ax.set_xlabel(r\"${x}$\", fontsize=26, color='black', fontdict={'weight': 'bold'})\n",
    "ax.set_ylabel(r\"${u(x, t)}$\", fontsize=26, color='black', fontdict={'weight': 'bold'})\n",
    "\n",
    "# Set the title with bold font weight\n",
    "ax.set_title(r\"${t = 0.83}$\", fontsize=26, color='black', fontweight='bold')\n",
    "\n",
    "# Set the number of ticks for x-axis and y-axis to 3\n",
    "ax.set_xticks([-1, 0, 1])\n",
    "ax.set_yticks([-1, 0, 1])\n",
    "\n",
    "# Set tick labels fontweight to bold and increase font size\n",
    "ax.tick_params(axis='both', which='major', labelsize=20, width=2, length=10)\n",
    "\n",
    "# # Set the fontweight for tick labels to bold\n",
    "# for tick in ax.get_xticklabels() + ax.get_yticklabels():\n",
    "#     tick.set_weight('bold')\n",
    "\n",
    "# Set the spines linewidth to bold\n",
    "ax.spines['top'].set_linewidth(2)\n",
    "ax.spines['right'].set_linewidth(2)\n",
    "ax.spines['bottom'].set_linewidth(2)\n",
    "ax.spines['left'].set_linewidth(2)\n",
    "\n",
    "# Set the legend\n",
    "# ax.legend()\n",
    "\n",
    "plt.savefig('LEM_0.83_20.pdf', dpi=500, bbox_inches=\"tight\")\n",
    "#plt.savefig('lem_0.83_20.png', dpi=500, bbox_inches=\"tight\")\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d96305e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Create the figure and axis objects with reduced width\n",
    "fig, ax = plt.subplots(figsize=(5, 5))  # You can adjust the width (7 inches) and height (5 inches) as needed\n",
    "\n",
    "\n",
    "\n",
    "final_time_output = prediction_tensor[-2, :]\n",
    "final_out = final_time_output.detach().numpy().reshape(-1, 1)\n",
    "final_true = u_1[:, -2].reshape(-1, 1)\n",
    "\n",
    "# Plot the data with red and blue lines, one with dotted and one with solid style\n",
    "ax.plot(x, final_out, color='red', linestyle='dotted', linewidth=12, label='Prediction')\n",
    "ax.plot(x, final_true, color='blue', linestyle='solid', linewidth=7, label='True')\n",
    "\n",
    "\n",
    "# Set the axis labels with bold font weight\n",
    "ax.set_xlabel(r\"${x}$\", fontsize=26, color='black', fontdict={'weight': 'bold'})\n",
    "ax.set_ylabel(r\"${u(x, t)}$\", fontsize=26, color='black', fontdict={'weight': 'bold'})\n",
    "\n",
    "# Set the title with bold font weight\n",
    "ax.set_title(r\"${t = 0.98}$\", fontsize=26, color='black', fontweight='bold')\n",
    "\n",
    "# Set the number of ticks for x-axis and y-axis to 3\n",
    "ax.set_xticks([-1, 0, 1])\n",
    "ax.set_yticks([-1, 0, 1])\n",
    "\n",
    "# Set tick labels fontweight to bold and increase font size\n",
    "ax.tick_params(axis='both', which='major', labelsize=20, width=2, length=10)\n",
    "\n",
    "# # Set the fontweight for tick labels to bold\n",
    "# for tick in ax.get_xticklabels() + ax.get_yticklabels():\n",
    "#     tick.set_weight('bold')\n",
    "\n",
    "# Set the spines linewidth to bold\n",
    "ax.spines['top'].set_linewidth(2)\n",
    "ax.spines['right'].set_linewidth(2)\n",
    "ax.spines['bottom'].set_linewidth(2)\n",
    "ax.spines['left'].set_linewidth(2)\n",
    "\n",
    "# Set the legend\n",
    "# ax.legend()\n",
    "\n",
    "plt.savefig('LEM_0.98_20.pdf', dpi=500, bbox_inches=\"tight\")\n",
    "#plt.savefig('lem_0.98_20.png', dpi=500, bbox_inches=\"tight\")\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d962cd38",
   "metadata": {},
   "source": [
    "### Contour plot where 80 percent for PINN solution and 20 percent for lem solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5011fef9",
   "metadata": {},
   "source": [
    "### Exact contour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6ac2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FixedLocator\n",
    "\n",
    "# Assuming you have defined concatenated_tensor as a PyTorch tensor\n",
    "# concatenated_tensor = torch.cat((tensor1, tensor2), dim=0)\n",
    "\n",
    "# Convert concatenated_tensor to a NumPy array\n",
    "concatenated_array = u_1.T\n",
    "\n",
    "# Define custom color levels\n",
    "x = np.linspace(-1, 1, concatenated_array.shape[1])  # Replace 0 and 1 with your actual x range\n",
    "t = np.linspace(0, 1, concatenated_array.shape[0])  # Replace 0 and 1 with your actual t range\n",
    "X, T = np.meshgrid(x, t)\n",
    "\n",
    "# Define custom color levels using the minimum and maximum from the NumPy array\n",
    "c_levels = np.linspace(np.min(concatenated_array), np.max(concatenated_array), 400)\n",
    "\n",
    "# Plot the contour with interpolated data\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.pcolormesh(T, X, concatenated_array, shading='auto', cmap='coolwarm')\n",
    "\n",
    "# Set the fontweight for axis labels to regular (not bold)\n",
    "plt.xlabel(\"$t$\", fontsize=26)\n",
    "plt.ylabel(\"$x$\", fontsize=26)\n",
    "plt.title(\"$u(x, t)$\", fontsize=26)\n",
    "\n",
    "# Set tick labels fontweight to regular (not bold) and increase font size\n",
    "plt.tick_params(axis='both', which='major', labelsize=20, width=3, length=10)\n",
    "\n",
    "# Set the fontweight for tick labels to regular (not bold)\n",
    "for tick in plt.gca().get_xticklabels() + plt.gca().get_yticklabels():\n",
    "    tick.set_weight('normal')\n",
    "\n",
    "# Set the number of ticks for x-axis and y-axis to 5\n",
    "num_ticks = 5\n",
    "x_ticks = np.linspace(np.min(T), np.max(T), num_ticks)\n",
    "y_ticks = np.linspace(np.min(X), np.max(X), num_ticks)\n",
    "\n",
    "plt.gca().xaxis.set_major_locator(FixedLocator(x_ticks))\n",
    "plt.gca().yaxis.set_major_locator(FixedLocator(y_ticks))\n",
    "\n",
    "cbar1 = plt.colorbar()\n",
    "# Set the number of ticks for the color bar with uniformly distributed numbers\n",
    "num_ticks = 5\n",
    "c_ticks = np.linspace(np.min(concatenated_array), np.max(concatenated_array), num_ticks)\n",
    "cbar1.set_ticks(c_ticks)\n",
    "\n",
    "# Set the fontweight and fontsize for color bar tick labels\n",
    "for t in cbar1.ax.get_yticklabels():\n",
    "    t.set_weight('normal')\n",
    "    t.set_fontsize(26)  # Increase the font size for color bar tick labels\n",
    "\n",
    "# Increase the size of numbers on axis and color bar\n",
    "plt.xticks(fontsize=26)\n",
    "plt.yticks(fontsize=26)\n",
    "\n",
    "# Increase the tick size and width of the color bar\n",
    "cbar1.ax.tick_params(axis='both', which='major', labelsize=30, width=3,  length=10)\n",
    "\n",
    "#plt.savefig('Contour_Exact.pdf', dpi=500, bbox_inches=\"tight\")\n",
    "plt.savefig('contour_exact.jpeg', dpi=500, bbox_inches=\"tight\")\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c034dcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FixedLocator\n",
    "\n",
    "# Assuming you have defined concatenated_tensor as a PyTorch tensor\n",
    "# concatenated_tensor = torch.cat((tensor1, tensor2), dim=0)\n",
    "\n",
    "# Convert concatenated_tensor to a NumPy array\n",
    "concatenated_array = concatenated_tensor.numpy()\n",
    "\n",
    "# Define custom color levels\n",
    "x = np.linspace(-1, 1, concatenated_array.shape[1])  # Replace 0 and 1 with your actual x range\n",
    "t = np.linspace(0, 1, concatenated_array.shape[0])  # Replace 0 and 1 with your actual t range\n",
    "X, T = np.meshgrid(x, t1)\n",
    "\n",
    "# Define custom color levels using the minimum and maximum from the NumPy array\n",
    "c_levels = np.linspace(np.min(concatenated_array), np.max(concatenated_array), 400)\n",
    "\n",
    "# Plot the contour with interpolated data\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.pcolormesh(T, X, concatenated_array, shading='auto', cmap='coolwarm')\n",
    "\n",
    "# Set the fontweight for axis labels to regular (not bold)\n",
    "plt.xlabel(\"$t$\", fontsize=26)\n",
    "plt.ylabel(\"$x$\", fontsize=26)\n",
    "plt.title(\"$u(x, t)$\", fontsize=26)\n",
    "\n",
    "# Set tick labels fontweight to regular (not bold) and increase font size\n",
    "plt.tick_params(axis='both', which='major', labelsize=20, width=3, length=10)\n",
    "\n",
    "# Set the fontweight for tick labels to regular (not bold)\n",
    "for tick in plt.gca().get_xticklabels() + plt.gca().get_yticklabels():\n",
    "    tick.set_weight('normal')\n",
    "\n",
    "# Set the number of ticks for x-axis and y-axis to 5\n",
    "num_ticks = 5\n",
    "x_ticks = np.linspace(np.min(T), np.max(T), num_ticks)\n",
    "y_ticks = np.linspace(np.min(X), np.max(X), num_ticks)\n",
    "\n",
    "plt.gca().xaxis.set_major_locator(FixedLocator(x_ticks))\n",
    "plt.gca().yaxis.set_major_locator(FixedLocator(y_ticks))\n",
    "\n",
    "cbar1 = plt.colorbar()\n",
    "# Set the number of ticks for the color bar with uniformly distributed numbers\n",
    "num_ticks = 5\n",
    "c_ticks = np.linspace(np.min(concatenated_array), np.max(concatenated_array), num_ticks)\n",
    "cbar1.set_ticks(c_ticks)\n",
    "\n",
    "# Set the fontweight and fontsize for color bar tick labels\n",
    "for t in cbar1.ax.get_yticklabels():\n",
    "    t.set_weight('normal')\n",
    "    t.set_fontsize(26)  # Increase the font size for color bar tick labels\n",
    "\n",
    "# Increase the size of numbers on axis and color bar\n",
    "plt.xticks(fontsize=26)\n",
    "plt.yticks(fontsize=26)\n",
    "\n",
    "# Increase the tick size and width of the color bar\n",
    "cbar1.ax.tick_params(axis='both', which='major', labelsize=30, width=3,  length=10)\n",
    "\n",
    "# Add a dotted line at t = 0.8\n",
    "plt.axvline(x=0.8, color='black', linestyle='dotted', linewidth=5)\n",
    "\n",
    "#plt.savefig('Contour_LEM_20.pdf', dpi=500, bbox_inches=\"tight\")\n",
    "plt.savefig('contour_LEM_20.jpeg', dpi=500, bbox_inches=\"tight\")\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ab04a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
